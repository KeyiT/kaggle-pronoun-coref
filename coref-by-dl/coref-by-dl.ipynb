{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2440b4a26da21815c0b967d0a3b8d6b9d734add2"
   },
   "source": [
    "This kernel implements 4 DL models for coreference resolution. All the model in this kernel are Non-RNN Based DL models.\n",
    "\n",
    "Features extraction used in this kernel follows Clark and Mannings work: https://nlp.stanford.edu/pubs/clark2016improving.pdf\n",
    "If you are interested in RNN based End2End coreference solution model, please check this kernel: https://www.kaggle.com/keyit92/end2end-coref-resolution-by-attention-rnn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/keyitang/miniconda3/envs/kaggle_pronoun/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.DS_Store', 'gendered-pronoun-resolution', 'gap-coreference']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/keyitang/miniconda3/envs/kaggle_pronoun/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "import gc\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "DATA_ROOT = '../input/'\n",
    "GAP_DATA_FOLDER = os.path.join(DATA_ROOT, 'gap-coreference')\n",
    "SUB_DATA_FOLDER = os.path.join(DATA_ROOT, 'gendered-pronoun-resolution')\n",
    "FAST_TEXT_DATA_FOLDER = os.path.join(DATA_ROOT, 'fasttext-crawl-300d-2m')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "461cb23b791e2d210e712c933e62de59d19aa20d"
   },
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "e42e2e7f636cf0702cc472f3d855b451554927dd"
   },
   "outputs": [],
   "source": [
    "test_df_path = os.path.join(GAP_DATA_FOLDER, 'gap-development.tsv')\n",
    "train_df_path = os.path.join(GAP_DATA_FOLDER, 'gap-test.tsv')\n",
    "dev_df_path = os.path.join(GAP_DATA_FOLDER, 'gap-validation.tsv')\n",
    "\n",
    "train_df = pd.read_csv(train_df_path, sep='\\t')\n",
    "test_df = pd.read_csv(test_df_path, sep='\\t')\n",
    "dev_df = pd.read_csv(dev_df_path, sep='\\t')\n",
    "\n",
    "# pd.options.display.max_colwidth = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "2eb32fae335b77dae0a60ade52b7ea0a32d8cb3d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>Pronoun</th>\n",
       "      <th>Pronoun-offset</th>\n",
       "      <th>A</th>\n",
       "      <th>A-offset</th>\n",
       "      <th>A-coref</th>\n",
       "      <th>B</th>\n",
       "      <th>B-offset</th>\n",
       "      <th>B-coref</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test-1</td>\n",
       "      <td>Upon their acceptance into the Kontinental Hoc...</td>\n",
       "      <td>His</td>\n",
       "      <td>383</td>\n",
       "      <td>Bob Suter</td>\n",
       "      <td>352</td>\n",
       "      <td>False</td>\n",
       "      <td>Dehner</td>\n",
       "      <td>366</td>\n",
       "      <td>True</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Jeremy_Dehner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test-2</td>\n",
       "      <td>Between the years 1979-1981, River won four lo...</td>\n",
       "      <td>him</td>\n",
       "      <td>430</td>\n",
       "      <td>Alonso</td>\n",
       "      <td>353</td>\n",
       "      <td>True</td>\n",
       "      <td>Alfredo Di St*fano</td>\n",
       "      <td>390</td>\n",
       "      <td>False</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Norberto_Alonso</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test-3</td>\n",
       "      <td>Though his emigration from the country has aff...</td>\n",
       "      <td>He</td>\n",
       "      <td>312</td>\n",
       "      <td>Ali Aladhadh</td>\n",
       "      <td>256</td>\n",
       "      <td>True</td>\n",
       "      <td>Saddam</td>\n",
       "      <td>295</td>\n",
       "      <td>False</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Aladhadh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test-4</td>\n",
       "      <td>At the trial, Pisciotta said: ``Those who have...</td>\n",
       "      <td>his</td>\n",
       "      <td>526</td>\n",
       "      <td>Alliata</td>\n",
       "      <td>377</td>\n",
       "      <td>False</td>\n",
       "      <td>Pisciotta</td>\n",
       "      <td>536</td>\n",
       "      <td>True</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Gaspare_Pisciotta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test-5</td>\n",
       "      <td>It is about a pair of United States Navy shore...</td>\n",
       "      <td>his</td>\n",
       "      <td>406</td>\n",
       "      <td>Eddie</td>\n",
       "      <td>421</td>\n",
       "      <td>True</td>\n",
       "      <td>Rock Reilly</td>\n",
       "      <td>559</td>\n",
       "      <td>False</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Chasers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID                                               Text Pronoun  \\\n",
       "0  test-1  Upon their acceptance into the Kontinental Hoc...     His   \n",
       "1  test-2  Between the years 1979-1981, River won four lo...     him   \n",
       "2  test-3  Though his emigration from the country has aff...      He   \n",
       "3  test-4  At the trial, Pisciotta said: ``Those who have...     his   \n",
       "4  test-5  It is about a pair of United States Navy shore...     his   \n",
       "\n",
       "   Pronoun-offset             A  A-offset  A-coref                   B  \\\n",
       "0             383     Bob Suter       352    False              Dehner   \n",
       "1             430        Alonso       353     True  Alfredo Di St*fano   \n",
       "2             312  Ali Aladhadh       256     True              Saddam   \n",
       "3             526       Alliata       377    False           Pisciotta   \n",
       "4             406         Eddie       421     True         Rock Reilly   \n",
       "\n",
       "   B-offset  B-coref                                             URL  \n",
       "0       366     True      http://en.wikipedia.org/wiki/Jeremy_Dehner  \n",
       "1       390    False    http://en.wikipedia.org/wiki/Norberto_Alonso  \n",
       "2       295    False           http://en.wikipedia.org/wiki/Aladhadh  \n",
       "3       536     True  http://en.wikipedia.org/wiki/Gaspare_Pisciotta  \n",
       "4       559    False            http://en.wikipedia.org/wiki/Chasers  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d60addb918fc181bd736f5497c3114dbf3d3bfd4"
   },
   "source": [
    "# Explore Features for Building Mention-Pair Distributed Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "177d5f8cca6584d7e542ea1ed6112e091e78d787"
   },
   "outputs": [],
   "source": [
    "from spacy.lang.en import English\n",
    "from spacy.pipeline import DependencyParser\n",
    "import spacy\n",
    "from nltk import Tree\n",
    "from category_encoders.one_hot import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "_uuid": "076788ce7be4a701d22cbf36e054f86d5f73a9d5"
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1c8b363cd5401b2693fead76b18157e82996c543"
   },
   "source": [
    "## Clean Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f0792301d7952c11af76ad9f67373ecd54d0deef"
   },
   "source": [
    "### Clean up Entity Names\n",
    "Replace Entity Names A and B by Alice and Bob."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "3c822c0bbebcd4c4483cc6f01bed38dd08fb8f98"
   },
   "outputs": [],
   "source": [
    "A_NAME = 'Alice'\n",
    "B_NAME = 'Bob'\n",
    "\n",
    "def find_all_substring(a_str, sub):\n",
    "    start = 0\n",
    "    result = list()\n",
    "    while True:\n",
    "        start = a_str.find(sub, start)\n",
    "        if start == -1:\n",
    "            return result\n",
    "        result.append(start)\n",
    "        start += len(sub) # use start += 1 to find overlapping matches\n",
    "\n",
    "def _update_offset(text, old_, new_, offset):\n",
    "    len_in = len(new_) - len(old_)\n",
    "    text_ = text[0:offset]\n",
    "    return offset + len_in * len(find_all_substring(text_, old_))\n",
    "    \n",
    "def replace_entity_name(text, a_name, b_name, a_offset, b_offset, p_offset):\n",
    "    # replace the whole name\n",
    "    a_offset = _update_offset(text, a_name, A_NAME, a_offset)\n",
    "    b_offset = _update_offset(text, a_name, A_NAME, b_offset)\n",
    "    p_offset = _update_offset(text, a_name, A_NAME, p_offset)\n",
    "    text = text.replace(a_name, A_NAME)\n",
    "\n",
    "    a_offset = _update_offset(text, b_name, B_NAME, a_offset)\n",
    "    b_offset = _update_offset(text, b_name, B_NAME, b_offset)\n",
    "    p_offset = _update_offset(text, b_name, B_NAME, p_offset)\n",
    "    text = text.replace(b_name, B_NAME)\n",
    "    \n",
    "    # replace sub name\n",
    "    a_name_list = a_name.strip().split(\" \")\n",
    "    b_name_list = b_name.strip().split(\" \")\n",
    "    for a_subname in a_name_list:\n",
    "        a_offset = _update_offset(text, a_subname, A_NAME, a_offset)\n",
    "        b_offset = _update_offset(text, a_subname, A_NAME, b_offset)\n",
    "        p_offset = _update_offset(text, a_subname, A_NAME, p_offset)\n",
    "        text = text.replace(a_subname, A_NAME)\n",
    "    for b_subname in b_name_list:\n",
    "        a_offset = _update_offset(text, b_subname, B_NAME, a_offset)\n",
    "        b_offset = _update_offset(text, b_subname, B_NAME, b_offset)\n",
    "        p_offset = _update_offset(text, b_subname, B_NAME, p_offset)\n",
    "        text = text.replace(a_subname, B_NAME)\n",
    "    \n",
    "    return text, a_offset, b_offset, p_offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "ad665933d75682de36494c845f079aaa34ba58af"
   },
   "outputs": [],
   "source": [
    "def entity_replace_func(row):\n",
    "    text, a_offset, b_offset, p_offset = replace_entity_name(\n",
    "        row['Text'], row['A'], row['B'], row['A-offset'], row['B-offset'], row['Pronoun-offset']\n",
    "    )\n",
    "    \n",
    "    row_ = row.copy()\n",
    "    row_['Text'] = text\n",
    "    row_['A'] = A_NAME\n",
    "    row_['B'] = B_NAME\n",
    "    row_['A-offset'] = a_offset\n",
    "    row_['B-offset'] = b_offset\n",
    "    row_['Pronoun-offset'] = p_offset\n",
    "    \n",
    "    return row_\n",
    "\n",
    "train_df = train_df.apply(entity_replace_func, axis=1)\n",
    "test_df = test_df.apply(entity_replace_func, axis=1)\n",
    "dev_df = dev_df.apply(entity_replace_func, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7118c61dcbdb24ebeee9f2d43105721b210cf9b8"
   },
   "source": [
    "## Train POS Tag Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "30086e92d8149598473adee88bb7e6310726f300"
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "893ce46e9cd41a0eec13ae6ee6c03c513d466148"
   },
   "outputs": [],
   "source": [
    "def pos_tags(text):\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    return [tok_.pos_ for tok_ in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "335e300d73fef09a5302114e2b02b215cc5b21eb"
   },
   "outputs": [],
   "source": [
    "all_texts = list(train_df['Text'].values.tolist() + test_df['Text'].values.tolist() + dev_df['Text'].values.tolist())\n",
    "pos_tags = [pos_tags(text_) for text_ in all_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "b9e42b302ea02919560d83fa506a378bbb0020ec"
   },
   "outputs": [],
   "source": [
    "pos_emb_size = 16\n",
    "pos_w2v = Word2Vec(pos_tags, size=pos_emb_size, min_count=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "29aa143f16f3aa13fc8b6bdc6bd785c05a3059da"
   },
   "source": [
    "## Embedding Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f8cef73c1ec7c1cb47bd0471cda9a31c3c297f20"
   },
   "source": [
    "Follow the idea from the work by Clark and Manning, extract word embedding of head word, dependency parent, first word, last word, two preceding words and two following words of the mention.  Average word embeding of the five preceding words, five following words, all words in the mention, all words in the sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c89b58ad8418cb71f6bec672e5787c71b4905ea9"
   },
   "source": [
    "### Parse Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "fb35c0c194fc8520601cdc6385d523109f91a563"
   },
   "outputs": [],
   "source": [
    "def bs_(list_, target_):\n",
    "    lo, hi = 0, len(list_) -1\n",
    "    \n",
    "    while lo < hi:\n",
    "        mid = lo + int((hi - lo) / 2)\n",
    "        \n",
    "        if target_ < list_[mid]:\n",
    "            hi = mid\n",
    "        elif target_ > list_[mid]:\n",
    "            lo = mid + 1\n",
    "        else:\n",
    "            return mid\n",
    "    return lo\n",
    "\n",
    "def ohe_dist(dist, buckets):\n",
    "    idx = bs_(buckets, dist)\n",
    "    oh = np.zeros(shape=(len(buckets),), dtype=np.float32)\n",
    "    oh[idx] = 1\n",
    "    \n",
    "    return oh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "d6b32ea0633dd9cceb551115f56f0ef94ee5b91c"
   },
   "outputs": [],
   "source": [
    "def to_nltk_tree(node):\n",
    "    if node.n_lefts + node.n_rights > 0:\n",
    "        return Tree(node.orth_, [to_nltk_tree(child) for child in node.children])\n",
    "    else:\n",
    "        return node.orth_\n",
    "\n",
    "def bs(list_, target_):\n",
    "    lo, hi = 0, len(list_) -1\n",
    "    \n",
    "    while lo < hi:\n",
    "        mid = lo + int((hi - lo) / 2)\n",
    "        \n",
    "        if target_ < list_[mid]:\n",
    "            hi = mid\n",
    "        elif target_ > list_[mid]:\n",
    "            lo = mid + 1\n",
    "        else:\n",
    "            return mid + 1\n",
    "    return lo\n",
    "\n",
    "def _get_preceding_words(tokens, offset, k):\n",
    "    start = offset - k\n",
    "    \n",
    "    precedings = [None] * max(0, 0-start)\n",
    "    start = max(0, start)\n",
    "    precedings += tokens[start: offset]\n",
    "    \n",
    "    return precedings\n",
    "\n",
    "def _get_following_words(tokens, offset, k):\n",
    "    end = offset + k\n",
    "    \n",
    "    followings = [None] * max(0, end - len(tokens))\n",
    "    end = min(len(tokens), end)\n",
    "    followings += tokens[offset: end]\n",
    "    \n",
    "    return followings\n",
    "        \n",
    "\n",
    "def extrac_embed_features_tokens(text, char_offset):\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    # char offset to token offset\n",
    "    lens = [token.idx for token in doc]\n",
    "    mention_offset = bs(lens, char_offset) - 1\n",
    "    # mention_word\n",
    "    mention = doc[mention_offset]\n",
    "    \n",
    "    # token offset to sentence offset\n",
    "    lens = [len(sent) for sent in doc.sents]\n",
    "    acc_lens = [len_ for len_ in lens]\n",
    "    pre_len = 0\n",
    "    for i in range(0, len(acc_lens)):\n",
    "        pre_len += acc_lens[i]\n",
    "        acc_lens[i] = pre_len\n",
    "    sent_index = bs(acc_lens, mention_offset)\n",
    "    # mention sentence\n",
    "    sent = list(doc.sents)[sent_index]\n",
    "    \n",
    "    # dependency parent\n",
    "    head = mention.head\n",
    "    \n",
    "    # last word and first word\n",
    "    first_word, last_word = sent[0], sent[-2]\n",
    "    \n",
    "    assert mention_offset >= 0\n",
    "    \n",
    "    # two preceding words and two following words\n",
    "    tokens = list(doc)\n",
    "    precedings2 = _get_preceding_words(tokens, mention_offset, 2)\n",
    "    followings2 = _get_following_words(tokens, mention_offset, 2)\n",
    "    \n",
    "    # five preceding words and five following words\n",
    "    precedings5 = _get_preceding_words(tokens, mention_offset, 5)\n",
    "    followings5 = _get_following_words(tokens, mention_offset, 5)\n",
    "    \n",
    "    # sentence words\n",
    "    sent_tokens = [token for token in sent]\n",
    "    \n",
    "     # buckets\n",
    "    bucket_pos = [0, 1, 2, 3, 4, 5, 8, 16, 32]\n",
    "    # absolute position in the sentence\n",
    "    sent_pos = mention_offset\n",
    "    if sent_index > 0:\n",
    "        sent_pos = mention_offset - acc_lens[sent_index-1]\n",
    "    sent_pos_oh = ohe_dist(sent_pos, bucket_pos)\n",
    "    sent_pos_inv = len(sent) - sent_pos - 1\n",
    "    assert sent_pos_inv >= 0\n",
    "    sent_pos_inv_oh = ohe_dist(sent_pos_inv, bucket_pos)\n",
    "    \n",
    "    return mention, head, first_word, last_word, precedings2, followings2, precedings5, followings5, sent_tokens, sent_pos_oh, sent_pos_inv_oh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2b791ce0f258c4dbdd1cd2d58b1d0a102a1ab3cc"
   },
   "source": [
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "_uuid": "ec45a77382b6840d6986589300efabbbc7d1eb69",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texts: \n",
      "Zoe Telford -- played the police officer girlfriend of Simon, Maggie. Dumped by Simon in the final episode of series 1, after he slept with Jenny, and is not seen again. Phoebe Thomas played Alice, Bob's friend and also a year 11 pupil in Simon's class. Dumped her boyfriend following Simon's advice after he wouldn't have sex with her but later realised this was due to him catching crabs off her friend Bob.\n",
      "\n",
      "Features:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "mention                                                        Alice\n",
       "parent                                                        played\n",
       "first_word                                                    Phoebe\n",
       "last_word                                                      class\n",
       "precedings2                                         [Thomas, played]\n",
       "followings2                                               [Alice, ,]\n",
       "precedings5                       [again, ., Phoebe, Thomas, played]\n",
       "followings5                              [Alice, ,, Bob, 's, friend]\n",
       "sent_tokens        [Phoebe, Thomas, played, Alice, ,, Bob, 's, fr...\n",
       "sent_pos_oh                             [0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
       "sent_pos_inv_oh                         [0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
       "dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Texts: \")\n",
    "text = test_df.iloc[0]['Text']\n",
    "print(text)\n",
    "\n",
    "#print(\"\\nDependency parsing trees: \")\n",
    "doc = nlp(text)\n",
    "#[to_nltk_tree(sent.root).pretty_print() for sent in doc.sents]\n",
    "\n",
    "print(\"\\nFeatures:\")\n",
    "mention, parent, first_word, last_word, precedings2, followings2, precedings5, followings5, sent_tokens, sent_pos_oh, sent_pos_inv_oh = extrac_embed_features_tokens(text, test_df.iloc[0]['A-offset'])\n",
    "features = pd.Series([str(feature) for feature in (mention, parent, first_word, last_word, precedings2, followings2, precedings5, followings5, sent_tokens, sent_pos_oh, sent_pos_inv_oh)], index=['mention', 'parent', 'first_word', 'last_word', 'precedings2', 'followings2', 'precedings5', 'followings5', 'sent_tokens', 'sent_pos_oh', 'sent_pos_inv_oh'])\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bfcd994bd7d0e7ec44248efb5370fe69fb201040"
   },
   "source": [
    "### Generate Embedding Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "0207e42f6dfaf422c1af0494a314fe8c2d78e21a"
   },
   "outputs": [],
   "source": [
    "num_embed_features = 11\n",
    "embed_dim = 384"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "c9704c8a0b69ffe9ddd011190e738084101c1da9"
   },
   "outputs": [],
   "source": [
    "def spacy_feats(tokens):\n",
    "    feats = list()\n",
    "    for token in tokens:\n",
    "        if token is None:\n",
    "            feats += [\"na\", \"na\", \"na\", \"na\"]\n",
    "            continue\n",
    "        feats += [token.dep_, token.shape_, str(token.is_alpha), str(token.is_stop)]\n",
    "    return feats\n",
    "    \n",
    "def create_embedding_features(df, text_column, offset_column):\n",
    "    text_offset_list = df[[text_column, offset_column]].values.tolist()\n",
    "    num_features = num_embed_features\n",
    "    \n",
    "    embed_feature_matrix = np.zeros(shape=(len(text_offset_list), num_features, embed_dim + pos_emb_size))\n",
    "    other_features = list()\n",
    "    pos_features = list()\n",
    "    for text_offset_index in range(len(text_offset_list)):\n",
    "        text_offset = text_offset_list[text_offset_index]\n",
    "        mention, parent, first_word, last_word, precedings2, followings2, precedings5, followings5, sent_tokens, sent_pos_oh, sent_pos_inv_oh = extrac_embed_features_tokens(text_offset[0], text_offset[1])\n",
    "        \n",
    "        feature_index = 0\n",
    "        embed_feature_matrix[text_offset_index, feature_index, :] = np.concatenate((mention.vector, pos_w2v[mention.pos_]))\n",
    "        feature_index += 1\n",
    "        embed_feature_matrix[text_offset_index, feature_index, :] = np.concatenate((parent.vector, pos_w2v[parent.pos_]))\n",
    "        feature_index += 1\n",
    "        embed_feature_matrix[text_offset_index, feature_index, :] = np.concatenate((first_word.vector, pos_w2v[first_word.pos_]))\n",
    "        feature_index += 1\n",
    "        embed_feature_matrix[text_offset_index, feature_index, :] = np.concatenate((last_word.vector, pos_w2v[last_word.pos_]))\n",
    "        feature_index += 1\n",
    "        embed_feature_matrix[text_offset_index, feature_index:feature_index+2, :] = np.asarray([np.concatenate((token.vector, pos_w2v[token.pos_])) if token is not None else np.zeros((embed_dim+pos_emb_size,)) for token in precedings2])\n",
    "        feature_index += len(precedings2)\n",
    "        embed_feature_matrix[text_offset_index, feature_index:feature_index+2, :] = np.asarray([np.concatenate((token.vector, pos_w2v[token.pos_])) if token is not None else np.zeros((embed_dim+pos_emb_size,)) for token in followings2])\n",
    "        feature_index += len(followings2)\n",
    "        precedings5 = list(filter(\n",
    "            lambda token_: token_ is not None,\n",
    "            precedings5\n",
    "        ))\n",
    "        followings5 = list(filter(\n",
    "            lambda token_: token_ is not None,\n",
    "            followings5\n",
    "        ))\n",
    "        embed_feature_matrix[text_offset_index, feature_index, :] = np.mean(np.asarray([np.concatenate((token.vector, pos_w2v[token.pos_])) if token is not None else np.zeros((embed_dim+pos_emb_size,)) for token in precedings5]), axis=0)\n",
    "        feature_index += 1\n",
    "        embed_feature_matrix[text_offset_index, feature_index, :] = np.mean(np.asarray([np.concatenate((token.vector, pos_w2v[token.pos_])) if token is not None else np.zeros((embed_dim+pos_emb_size,)) for token in followings5]), axis=0)\n",
    "        feature_index += 1\n",
    "        embed_feature_matrix[text_offset_index, feature_index, :] = np.mean(np.asarray([np.concatenate((token.vector, pos_w2v[token.pos_])) for token in sent_tokens]), axis=0) if len(sent_tokens) > 0 else np.zeros((embed_dim+pos_emb_size,))\n",
    "        feature_index += 1\n",
    "        \n",
    "        other_features.append(list())\n",
    "        other_features[-1] += spacy_feats([mention, parent, first_word, last_word])\n",
    "        other_features[-1] += spacy_feats(precedings2)\n",
    "        other_features[-1] += spacy_feats(followings2)\n",
    "        \n",
    "        pos_features.append(np.concatenate((sent_pos_oh, sent_pos_inv_oh)))\n",
    "    \n",
    "    return embed_feature_matrix, other_features, np.asarray(pos_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2755927ba88262427347c567ae777c92510ffa68"
   },
   "source": [
    " ##  Position Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "15165f2b90503a90de589b37558ebcea28daa867"
   },
   "source": [
    "Encode the absolute positions in the sentence and the relative position between the pronoun and the entities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "9f3d21e9a626a3290c81c6bc98b817c3e47275be"
   },
   "outputs": [],
   "source": [
    "def extrac_positional_features(text, char_offset1, char_offset2):\n",
    "    doc = nlp(text)\n",
    "    max_len = 64\n",
    "    \n",
    "    # char offset to token offset\n",
    "    lens = [token.idx for token in doc]\n",
    "    mention_offset1 = bs(lens, char_offset1) - 1\n",
    "    mention_offset2 = bs(lens, char_offset2) - 1\n",
    "    \n",
    "    # token offset to sentence offset\n",
    "    lens = [len(sent) for sent in doc.sents]\n",
    "    acc_lens = [len_ for len_ in lens]\n",
    "    pre_len = 0\n",
    "    for i in range(0, len(acc_lens)):\n",
    "        pre_len += acc_lens[i]\n",
    "        acc_lens[i] = pre_len\n",
    "    sent_index1 = bs(acc_lens, mention_offset1)\n",
    "    sent_index2 = bs(acc_lens, mention_offset2)\n",
    "    \n",
    "    sent1 = list(doc.sents)[sent_index1]\n",
    "    sent2 = list(doc.sents)[sent_index2]\n",
    "    \n",
    "    # buckets\n",
    "    bucket_dist = [1, 2, 3, 4, 5, 8, 16, 32, 64]\n",
    "    \n",
    "    # relative distance\n",
    "    dist = mention_offset2 - mention_offset1\n",
    "    dist_oh = ohe_dist(dist, bucket_dist)\n",
    "    \n",
    "    return dist_oh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_uuid": "c1c14436f57e74e80ac4425f77df98768c71f7b9"
   },
   "outputs": [],
   "source": [
    "num_pos_features = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_uuid": "4a9ec346bff260b62ebea6d9223c6a11e683a9ee"
   },
   "outputs": [],
   "source": [
    "def create_dist_features(df, text_column, pronoun_offset_column, name_offset_column):\n",
    "    text_offset_list = df[[text_column, pronoun_offset_column, name_offset_column]].values.tolist()\n",
    "    num_features = num_pos_features\n",
    "    \n",
    "    pos_feature_matrix = np.zeros(shape=(len(text_offset_list), num_features))\n",
    "    for text_offset_index in range(len(text_offset_list)):\n",
    "        text_offset = text_offset_list[text_offset_index]\n",
    "        dist_oh = extrac_positional_features(text_offset[0], text_offset[1], text_offset[2])\n",
    "        \n",
    "        feature_index = 0\n",
    "        pos_feature_matrix[text_offset_index, feature_index:feature_index+len(dist_oh)] = np.asarray(dist_oh)\n",
    "        feature_index += len(dist_oh)\n",
    "#         pos_feature_matrix[text_offset_index, feature_index:feature_index+len(sent_pos_oh1)] = np.asarray(sent_pos_oh1)\n",
    "#         feature_index += len(sent_pos_oh1)\n",
    "#         pos_feature_matrix[text_offset_index, feature_index:feature_index+len(sent_pos_oh2)] = np.asarray(sent_pos_oh2)\n",
    "#         feature_index += len(sent_pos_oh2)\n",
    "#         pos_feature_matrix[text_offset_index, feature_index:feature_index+len(sent_pos_inv_oh1)] = np.asarray(sent_pos_inv_oh1)\n",
    "#         feature_index += len(sent_pos_inv_oh1)\n",
    "#         pos_feature_matrix[text_offset_index, feature_index:feature_index+len(sent_pos_inv_oh2)] = np.asarray(sent_pos_inv_oh2)\n",
    "#         feature_index += len(sent_pos_inv_oh2)\n",
    "    \n",
    "    return pos_feature_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "89203775726cd6d361161680c83a278717fd926e"
   },
   "source": [
    "### Generate Training, Validation and Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_uuid": "a6cd42d52bda7aaa12654031ec335c827cc104b2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/keyitang/miniconda3/envs/kaggle_pronoun/lib/python3.6/site-packages/ipykernel_launcher.py:22: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (316) into shape (400)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-a6581ccc219e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mp_emb_tra\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_feats_tra\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_pos_tra\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_embedding_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Text'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Pronoun-offset'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mp_emb_dev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_feats_dev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_pos_dev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_embedding_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Text'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Pronoun-offset'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mp_emb_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_feats_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_pos_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_embedding_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Text'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Pronoun-offset'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0ma_emb_tra\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_feats_tra\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_pos_tra\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_embedding_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Text'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'A-offset'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-b7fcbc444fde>\u001b[0m in \u001b[0;36mcreate_embedding_features\u001b[0;34m(df, text_column, offset_column)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mfeature_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0membed_feature_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtext_offset_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmention\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_w2v\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmention\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mfeature_index\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0membed_feature_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtext_offset_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_w2v\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (316) into shape (400)"
     ]
    }
   ],
   "source": [
    "p_emb_tra, p_feats_tra, p_pos_tra = create_embedding_features(train_df, 'Text', 'Pronoun-offset')\n",
    "p_emb_dev, p_feats_dev, p_pos_dev = create_embedding_features(dev_df, 'Text', 'Pronoun-offset')\n",
    "p_emb_test, p_feats_test, p_pos_test = create_embedding_features(test_df, 'Text', 'Pronoun-offset')\n",
    "\n",
    "a_emb_tra, a_feats_tra, a_pos_tra = create_embedding_features(train_df, 'Text', 'A-offset')\n",
    "a_emb_dev, a_feats_dev, a_pos_dev = create_embedding_features(dev_df, 'Text', 'A-offset')\n",
    "a_emb_test, a_feats_test, a_pos_test = create_embedding_features(test_df, 'Text', 'A-offset')\n",
    "\n",
    "b_emb_tra, b_feats_tra, b_pos_tra = create_embedding_features(train_df, 'Text', 'B-offset')\n",
    "b_emb_dev, b_feats_dev, b_pos_dev = create_embedding_features(dev_df, 'Text', 'B-offset')\n",
    "b_emb_test, b_feats_test, b_pos_test = create_embedding_features(test_df, 'Text', 'B-offset')\n",
    "\n",
    "pa_dist_tra = create_dist_features(train_df, 'Text', 'Pronoun-offset', 'A-offset')\n",
    "pa_dist_dev = create_dist_features(dev_df, 'Text', 'Pronoun-offset', 'A-offset')\n",
    "pa_dist_test = create_dist_features(test_df, 'Text', 'Pronoun-offset', 'A-offset')\n",
    "\n",
    "pb_dist_tra = create_dist_features(train_df, 'Text', 'Pronoun-offset', 'B-offset')\n",
    "pb_dist_dev = create_dist_features(dev_df, 'Text', 'Pronoun-offset', 'B-offset')\n",
    "pb_dist_test = create_dist_features(test_df, 'Text', 'Pronoun-offset', 'B-offset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "46d7c4f9c36e8c3a4354b55e63b75b9d5c1a3572"
   },
   "outputs": [],
   "source": [
    "# One hot encode other features\n",
    "feats_encoder = OneHotEncoder(return_df=False)\n",
    "feats_encoder.fit(\n",
    "    p_feats_tra + p_feats_dev + p_feats_test + a_feats_tra + a_feats_dev + a_feats_test + b_feats_tra + b_feats_dev + b_feats_test\n",
    ")\n",
    "\n",
    "p_encode_tra = np.concatenate((feats_encoder.transform(p_feats_tra), p_pos_tra), axis=1)\n",
    "a_encode_tra = np.concatenate((feats_encoder.transform(a_feats_tra), a_pos_tra), axis=1)\n",
    "b_encode_tra = np.concatenate((feats_encoder.transform(b_feats_tra), b_pos_tra), axis=1)\n",
    "\n",
    "p_encode_test = np.concatenate((feats_encoder.transform(p_feats_test), p_pos_test), axis=1)\n",
    "a_encode_test = np.concatenate((feats_encoder.transform(a_feats_test), a_pos_test), axis=1)\n",
    "b_encode_test = np.concatenate((feats_encoder.transform(b_feats_test), b_pos_test), axis=1)\n",
    "\n",
    "p_encode_dev = np.concatenate((feats_encoder.transform(p_feats_dev), p_pos_dev), axis=1)\n",
    "a_encode_dev = np.concatenate((feats_encoder.transform(a_feats_dev), a_pos_dev), axis=1)\n",
    "b_encode_dev = np.concatenate((feats_encoder.transform(b_feats_dev), b_pos_dev), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a9c813e2dcddb0c4746f72b4521263ff9737669d"
   },
   "outputs": [],
   "source": [
    "def _row_to_y(row):\n",
    "    if row.loc['A-coref']:\n",
    "        return 0\n",
    "    if row.loc['B-coref']:\n",
    "        return 1\n",
    "    return 2\n",
    "\n",
    "y_tra = train_df.apply(_row_to_y, axis=1)\n",
    "y_dev = dev_df.apply(_row_to_y, axis=1)\n",
    "y_test = test_df.apply(_row_to_y, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "dcf1a4a4d3deb6710d3e099e91279fb1392921af"
   },
   "outputs": [],
   "source": [
    "X_train = [p_emb_tra, a_emb_tra, b_emb_tra, p_encode_tra, a_encode_tra, b_encode_tra, pa_dist_tra, pb_dist_tra]\n",
    "X_dev = [p_emb_dev, a_emb_dev, b_emb_dev, p_encode_dev, a_encode_dev, b_encode_dev, pa_dist_dev, pb_dist_dev]\n",
    "X_test = [p_emb_test, a_emb_test, b_emb_test, p_encode_test, a_encode_test, b_encode_test, pa_dist_test, pb_dist_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f61ce2fb9b0cad8b34832c56a0e7d24a2cbc7117"
   },
   "source": [
    "# Define DL Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "_uuid": "17c1f6e65072a302ef0186032433105c72dafffe"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras import backend\n",
    "from keras import layers\n",
    "from keras import models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "33ee19bc3e355ea58dd27bd5c373a13682536dd4"
   },
   "source": [
    "## Coattention Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0a640bb122b0821206432fa99d39cd8fe70eecbb"
   },
   "source": [
    "#### Define Co-attention Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "_uuid": "cb3cacc8e7dc332a6b5cacf3d733f314b7f03cba"
   },
   "outputs": [],
   "source": [
    "from keras import initializers, regularizers, constraints, activations\n",
    "from keras.engine import Layer\n",
    "import keras.backend as K\n",
    "from keras.layers import merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "_uuid": "3830a23390eaf527992b3676e03857699969957e"
   },
   "outputs": [],
   "source": [
    "def _dot_product(x, kernel):\n",
    "    \"\"\"\n",
    "    Wrapper for dot product operation, in order to be compatible with both\n",
    "    Theano and Tensorflow\n",
    "    Args:\n",
    "        x (): input\n",
    "        kernel (): weights\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    if K.backend() == 'tensorflow':\n",
    "        # todo: check that this is correct\n",
    "        return K.squeeze(K.dot(x, K.expand_dims(kernel)), axis=-1)\n",
    "    else:\n",
    "        return K.dot(x, kernel)\n",
    "    \n",
    "\n",
    "class CoAttentionWeight(Layer):\n",
    "    \"\"\"\n",
    "        Unnormalized Co-Attention operation for temporal data.\n",
    "        Supports Masking.\n",
    "        Follows the work of Ankur et al. [https://aclweb.org/anthology/D16-1244]\n",
    "        \"A Decomposable Attention Model for Natural Language Inference\"\n",
    "        # Input shape\n",
    "            List of 2 3D tensor with shape: `(samples, steps1, features1)` and `(samples, steps2, features2)`.\n",
    "        # Output shape\n",
    "            3D tensor with shape: `(samples, steps1, step2)`.\n",
    "        :param kwargs:\n",
    "        \"\"\"\n",
    "\n",
    "    def __init__(self, W_regularizer=None, W_constraint=None, **kwargs):\n",
    "\n",
    "        self.init = initializers.get('glorot_uniform')\n",
    "\n",
    "        self.W_regularizer = regularizers.get(W_regularizer)\n",
    "        self.W_constraint = constraints.get(W_constraint)\n",
    "\n",
    "        super(CoAttentionWeight, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(CoAttentionWeight, self).build(input_shape)\n",
    "\n",
    "        if not isinstance(input_shape, list) or len(input_shape) != 2:\n",
    "            raise ValueError('A `Coattention` layer should be called '\n",
    "                             'on a list of 2 inputs.')\n",
    "        shape1 = list(input_shape[0])\n",
    "        shape2 = list(input_shape[1])\n",
    "\n",
    "        if shape1[-1] != shape2[-1]:\n",
    "            raise ValueError(\"The last dimention of input tensors must be same. \"\n",
    "                             \"Otherwise use RemappedCoattentionWeight instead\")\n",
    "\n",
    "        self.W = self.add_weight((shape1[-1], shape1[-1]),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_W'.format(self.name),\n",
    "                                 regularizer=self.W_regularizer,\n",
    "                                 constraint=self.W_constraint)\n",
    "\n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        # pass the mask to the next layers\n",
    "        return input_mask\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        if len(inputs) != 2:\n",
    "            raise ValueError('A `Subtract` layer should be called '\n",
    "                             'on exactly 2 inputs')\n",
    "\n",
    "        x1, x2 = inputs[0], inputs[1]\n",
    "\n",
    "        if x1.shape[-1] != x2.shape[-1]:\n",
    "            raise ValueError(\"The last dimention of input tensors must be same. \"\n",
    "                             \"Otherwise use RemappedCoattentionWeight instead\")\n",
    "\n",
    "        # atten = exp(u1 W u2^T)\n",
    "        atten = _dot_product(x1, self.W)\n",
    "        atten = K.batch_dot(atten, x2, axes=[2, 2])\n",
    "        atten = K.exp(atten)\n",
    "\n",
    "        return atten\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        if not isinstance(input_shape, list) or len(input_shape) != 2:\n",
    "            raise ValueError('A `Coattention` layer should be called '\n",
    "                             'on a list of 2 inputs.')\n",
    "        shape1 = list(input_shape[0])\n",
    "        shape2 = list(input_shape[1])\n",
    "\n",
    "        if shape1[0] != shape2[0]:\n",
    "            raise ValueError(\"batch size must be same\")\n",
    "\n",
    "        return shape1[0], shape1[1], shape2[1]\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'W_regularizer': regularizers.serialize(self.W_regularizer),\n",
    "            'W_constraint': constraints.serialize(self.W_constraint),\n",
    "        }\n",
    "        base_config = super(CoAttentionWeight, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "    \n",
    "    \n",
    "class RemappedCoAttentionWeight(Layer):\n",
    "    \"\"\"\n",
    "        Unnormalized Co-Attention operation for temporal data.\n",
    "        Supports Masking.\n",
    "        Follows the work of Ankur et al. [https://aclweb.org/anthology/D16-1244]\n",
    "        \"A Decomposable Attention Model for Natural Language Inference\"\n",
    "        # Input shape\n",
    "            List of 2 3D tensor with shape: `(samples, steps1, features1)` and `(samples, steps2, features2)`.\n",
    "        # Output shape\n",
    "            3D tensor with shape: `(samples, steps1, step2)`.\n",
    "        :param kwargs:\n",
    "        \"\"\"\n",
    "\n",
    "    def __init__(self, model_size, activation='sigmoid',\n",
    "                 W1_regularizer=None, W2_regularizer=None, b1_regularizer=None, b2_regularizer=None,\n",
    "                 W1_constraint=None, W2_constraint=None, b1_constraint=None, b2_constraint=None,\n",
    "                 bias1=True, bias2=True, **kwargs):\n",
    "\n",
    "        self.model_size = model_size\n",
    "        self.init = initializers.get('glorot_uniform')\n",
    "\n",
    "        self.W1_regularizer = regularizers.get(W1_regularizer)\n",
    "        self.W2_regularizer = regularizers.get(W2_regularizer)\n",
    "        self.b1_regularizer = regularizers.get(b1_regularizer)\n",
    "        self.b2_regularizer = regularizers.get(b2_regularizer)\n",
    "\n",
    "        self.W1_constraint = constraints.get(W1_constraint)\n",
    "        self.W2_constraint = constraints.get(W2_constraint)\n",
    "        self.b1_constraint = constraints.get(b1_constraint)\n",
    "        self.b2_constraint = constraints.get(b2_constraint)\n",
    "\n",
    "        self.bias1 = bias1\n",
    "        self.bias2 = bias2\n",
    "        self.activation = activations.get(activation)\n",
    "        super(RemappedCoAttentionWeight, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "\n",
    "        if len(input_shape) != 2:\n",
    "            raise ValueError(\"input must be a size two list which contains two tensors\")\n",
    "\n",
    "        shape1 = list(input_shape[0])\n",
    "        shape2 = list(input_shape[1])\n",
    "\n",
    "        self.W1 = self.add_weight((self.model_size, shape1[-1]),\n",
    "                                  initializer=self.init,\n",
    "                                  name='{}_W1'.format(self.name),\n",
    "                                  regularizer=self.W1_regularizer,\n",
    "                                  constraint=self.W1_constraint)\n",
    "\n",
    "        self.W2 = self.add_weight((self.model_size, shape2[-1]),\n",
    "                                  initializer=self.init,\n",
    "                                  name='{}_W2'.format(self.name),\n",
    "                                  regularizer=self.W2_regularizer,\n",
    "                                  constraint=self.W2_constraint)\n",
    "\n",
    "        if self.bias1:\n",
    "            self.b1 = self.add_weight((self.model_size,),\n",
    "                                      initializer='zero',\n",
    "                                      name='{}_b1'.format(self.name),\n",
    "                                      regularizer=self.b1_regularizer,\n",
    "                                      constraint=self.b1_constraint)\n",
    "\n",
    "        if self.bias2:\n",
    "            self.b2 = self.add_weight((self.model_size,),\n",
    "                                      initializer='zero',\n",
    "                                      name='{}_b2'.format(self.name),\n",
    "                                      regularizer=self.b2_regularizer,\n",
    "                                      constraint=self.b2_constraint)\n",
    "\n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        # pass the mask to the next layers\n",
    "        return input_mask\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        if len(inputs) != 2:\n",
    "            raise ValueError('A `Subtract` layer should be called '\n",
    "                             'on exactly 2 inputs')\n",
    "\n",
    "        x1, x2 = inputs[0], inputs[1]\n",
    "\n",
    "        # u = Wx + b\n",
    "        u1 = _dot_product(x1, self.W1)\n",
    "        if self.bias1:\n",
    "            u1 += self.b1\n",
    "\n",
    "        u2 = _dot_product(x2, self.W2)\n",
    "        if self.bias2:\n",
    "            u2 += self.b2\n",
    "\n",
    "        # u = Activation(Wx + b)\n",
    "        u1 = self.activation(u1)\n",
    "        u2 = self.activation(u2)\n",
    "\n",
    "        # atten = exp(u1 u2^T)\n",
    "        atten = K.batch_dot(u1, u2, axes=[2, 2])\n",
    "        atten = K.exp(atten)\n",
    "\n",
    "        return atten\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        if not isinstance(input_shape, list) or len(input_shape) != 2:\n",
    "            raise ValueError('A `Dot` layer should be called '\n",
    "                             'on a list of 2 inputs.')\n",
    "        shape1 = list(input_shape[0])\n",
    "        shape2 = list(input_shape[1])\n",
    "\n",
    "        if shape1[0] != shape2[0]:\n",
    "            raise ValueError(\"batch size must be same\")\n",
    "\n",
    "        return shape1[0], shape1[1], shape2[1]\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'activation': self.activation,\n",
    "            'model_size': self.model_size,\n",
    "            'W1_regularizer': regularizers.serialize(self.W1_regularizer),\n",
    "            'W2_regularizer': regularizers.serialize(self.W2_regularizer),\n",
    "            'b1_regularizer': regularizers.serialize(self.b1_regularizer),\n",
    "            'b2_regularizer': regularizers.serialize(self.b2_regularizer),\n",
    "            'W1_constraint': constraints.serialize(self.W1_constraint),\n",
    "            'W2_constraint': constraints.serialize(self.W2_constraint),\n",
    "            'b1_constraint': constraints.serialize(self.b1_constraint),\n",
    "            'b2_constraint': constraints.serialize(self.b2_constraint),\n",
    "            'bias1': self.bias1,\n",
    "            'bias2': self.bias2\n",
    "        }\n",
    "        base_config = super(RemappedCoAttentionWeight, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "    \n",
    "class FeatureNormalization(Layer):\n",
    "    \"\"\"\n",
    "        Normalize feature along a specific axis.\n",
    "        Supports Masking.\n",
    "\n",
    "        # Input shape\n",
    "            A ND tensor with shape: `(samples, feature1 ... featuresN).\n",
    "        # Output shape\n",
    "            ND tensor with shape: `(samples, feature1 ... featuresN)`.\n",
    "        :param kwargs:\n",
    "        \"\"\"\n",
    "\n",
    "    def __init__(self, axis=-1, **kwargs):\n",
    "\n",
    "        self.axis = axis\n",
    "        self.supports_masking = True\n",
    "        super(FeatureNormalization, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "\n",
    "        super(FeatureNormalization, self).build(input_shape)\n",
    "\n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        # don't pass the mask to the next layers\n",
    "        return None\n",
    "\n",
    "    def call(self, inputs, mask=None):\n",
    "        # apply mask after the exp. will be re-normalized next\n",
    "        if mask is not None:\n",
    "            # Cast the mask to floatX to avoid float64 upcasting in theano\n",
    "            a = K.cast(mask, K.floatx()) * inputs\n",
    "        else:\n",
    "            a = inputs\n",
    "\n",
    "        # in some cases especially in the early stages of training the sum may be almost zero\n",
    "        # and this results in NaN's. A workaround is to add a very small positive number ε to the sum.\n",
    "        # a /= K.cast(K.sum(a, axis=1, keepdims=True), K.floatx())\n",
    "        a /= K.cast(K.sum(a, axis=self.axis, keepdims=True) + K.epsilon(), K.floatx())\n",
    "        \n",
    "        return a\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'axis': self.axis\n",
    "        }\n",
    "        base_config = super(FeatureNormalization, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bf87bf600dac037777be8e3dda560ec65b6640a2"
   },
   "source": [
    "# Build and Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "_uuid": "03e8297383ee57a4a23c707a4a6c1cca13da1868"
   },
   "outputs": [],
   "source": [
    "from keras import callbacks as kc\n",
    "from keras import optimizers as ko\n",
    "from keras import initializers, regularizers, constraints\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import SVG\n",
    "\n",
    "\n",
    "from numpy.random import seed\n",
    "from tensorflow import set_random_seed\n",
    "\n",
    "seed(1)\n",
    "set_random_seed(2)\n",
    "\n",
    "histories = list()\n",
    "cos = list()\n",
    "model_paths = list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "059a938af1c45abaa8ea05181a41dc4431b7ec28"
   },
   "source": [
    "## Baseline Model MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f955f5dd9603b4148ab3054aafa0ff0caeea7eeb"
   },
   "outputs": [],
   "source": [
    "def build_mlp_model(\n",
    "    num_channels1, num_channels2, num_channels3, \n",
    "    num_features1, num_features2, num_features3, \n",
    "    feature_dim1, output_dim, mlp_dim, \n",
    "    mlp_depth=1, embed_dropout=0.5, drop_out=0.2, \n",
    "    return_customized_layers=False):\n",
    "    \"\"\"\n",
    "    Create A Multi-Layer Perceptron Model.\n",
    "    \n",
    "    inputs: \n",
    "        embeddings: [batch, num_embed_feature, embed_dims] * 3 ## pronoun, A, B\n",
    "        features: [batch, num_other_feature] * 3 ## pronoun, A, B\n",
    "        mention_pair_features: [batch, num_mention_pair_feature] * 2 ## pronoun-A, pronoun-B\n",
    "        \n",
    "    outputs: \n",
    "        [batch, num_classes] # in our case there should be 3 output classes: A, B, None\n",
    "        \n",
    "    :param output_dim: the output dimension size\n",
    "    :param model_dim: rrn dimension size\n",
    "    :param mlp_dim: the dimension size of fully connected layer\n",
    "    :param mlp_depth: the depth of fully connected layers\n",
    "    :param drop_out: dropout rate of fully connected layers\n",
    "    :param return_customized_layers: boolean, default=False\n",
    "        If True, return model and customized object dictionary, otherwise return model only\n",
    "    :return: keras model\n",
    "    \"\"\"\n",
    "\n",
    "    # inputs\n",
    "    inputs1 = list()\n",
    "    for fi in range(num_channels1):\n",
    "        inputs1.append(models.Input(shape=(num_features1, feature_dim1), dtype='float32', name='input1_' + str(fi)))\n",
    "        \n",
    "    inputs2 = list()\n",
    "    for fi in range(num_channels2):\n",
    "        inputs2.append(models.Input(shape=(num_features2,), dtype='float32', name='input2_' + str(fi)))\n",
    "        \n",
    "    inputs3 = list()\n",
    "    for fi in range(num_channels3):\n",
    "        inputs3.append(models.Input(shape=(num_features3,), dtype='float32', name='input3_' + str(fi)))\n",
    "        \n",
    "    features1_pip = models.Sequential()\n",
    "    features1_pip.add(layers.TimeDistributed(layers.Dropout(rate=embed_dropout, name=\"embed_dropout_layer\")))\n",
    "    features1_pip.add(layers.Flatten(name=\"embed_flatten_layer\"))\n",
    "    \n",
    "    x1 = [features1_pip(input_) for input_ in inputs1]\n",
    "    x2 = inputs2\n",
    "    x3 = inputs3\n",
    "    \n",
    "    x = layers.Concatenate(axis=1, name=\"concate_layer\")(x1+x2+x3)\n",
    "    \n",
    "    # MLP Layers\n",
    "    x = layers.BatchNormalization(name='batch_norm_layer')(x)\n",
    "    x = layers.Dropout(rate=drop_out, name=\"dropout_layer\")(x)\n",
    "        \n",
    "    for i in range(mlp_depth - 1):\n",
    "        x = layers.Dense(mlp_dim, activation='selu', kernel_initializer='lecun_normal', name='selu_layer' + str(i))(x)\n",
    "        x = layers.AlphaDropout(drop_out, name='alpha_layer' + str(i))(x)\n",
    "\n",
    "    outputs = layers.Dense(output_dim, activation=\"softmax\", name=\"softmax_layer0\")(x)\n",
    "\n",
    "    model = models.Model(inputs1 + inputs2 + inputs3, outputs)\n",
    "\n",
    "    if return_customized_layers:\n",
    "        return model, {}\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fba6b5bd600789437a97bfafde4a68b76eaac03b"
   },
   "source": [
    "### Build Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "569aa2476fe1cf893ba878b5c83cc37713f2460a"
   },
   "outputs": [],
   "source": [
    "num_channels1 = 3\n",
    "num_channels2 = 3\n",
    "num_channels3 = 2\n",
    "num_features1 = p_emb_tra.shape[1]\n",
    "num_features2 = p_encode_tra.shape[1]\n",
    "#num_features2 = p_pos_tra.shape[1]\n",
    "num_features3 = pa_dist_tra.shape[1]\n",
    "feature_dim1 = p_emb_tra.shape[2]\n",
    "output_dim = 3\n",
    "mlp_dim = 10\n",
    "mlp_depth=2\n",
    "embed_dropout=0.5\n",
    "drop_out=0.2\n",
    "return_customized_layers=True\n",
    "\n",
    "model, co = build_mlp_model(\n",
    "    num_channels1, num_channels2, num_channels3, \n",
    "    num_features1, num_features2, num_features3, \n",
    "    feature_dim1, output_dim, mlp_dim, \n",
    "    mlp_depth=mlp_depth, embed_dropout=embed_dropout, drop_out=drop_out, \n",
    "    return_customized_layers=return_customized_layers\n",
    ")\n",
    "\n",
    "cos.append(co)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "13dc8379c35b5b5cf24ee5a32a7358b934ce56ce"
   },
   "outputs": [],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fd91fac5c5a6a233f87b04702893bbb7c00991d3"
   },
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "06a0d8ced3f0959cec05212bd5fa51f373aacd83"
   },
   "outputs": [],
   "source": [
    "adam = ko.Nadam()\n",
    "model.compile(adam, loss=\"sparse_categorical_crossentropy\", metrics=[\"sparse_categorical_accuracy\"])\n",
    "\n",
    "file_path = \"best_mlp_model.hdf5\"\n",
    "check_point = kc.ModelCheckpoint(file_path, monitor = \"val_loss\", verbose = 1, save_best_only = True, mode = \"min\")\n",
    "early_stop = kc.EarlyStopping(monitor = \"val_loss\", mode = \"min\", patience=3)\n",
    "history = model.fit(X_train, y_tra, batch_size=20, epochs=20, validation_data=(X_dev, y_dev), callbacks = [check_point, early_stop])\n",
    "\n",
    "histories.append(np.min(np.asarray(history.history['val_loss'])))\n",
    "model_paths.append(file_path)\n",
    "\n",
    "del model, history\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "059a938af1c45abaa8ea05181a41dc4431b7ec28"
   },
   "source": [
    "## Remapped Model MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f955f5dd9603b4148ab3054aafa0ff0caeea7eeb"
   },
   "outputs": [],
   "source": [
    "def build_remap_mlp_model(\n",
    "    num_channels1, num_channels2, num_channels3, \n",
    "    num_features1, num_features2, num_features3, \n",
    "    feature_dim1, output_dim, model_dim1, model_dim2, model_dim3, mlp_dim, \n",
    "    mlp_depth=1, embed_dropout=0.5, drop_out=0.2, \n",
    "    return_customized_layers=False):\n",
    "    \"\"\"\n",
    "    Create A Multi-Layer Perceptron Model.\n",
    "    \n",
    "    inputs: \n",
    "        embeddings: [batch, num_embed_feature, embed_dims] * 3 ## pronoun, A, B\n",
    "        features: [batch, num_other_feature] * 3 ## pronoun, A, B\n",
    "        mention_pair_features: [batch, num_mention_pair_feature] * 2 ## pronoun-A, pronoun-B\n",
    "        \n",
    "    outputs: \n",
    "        [batch, num_classes] # in our case there should be 3 output classes: A, B, None\n",
    "        \n",
    "    :param output_dim: the output dimension size\n",
    "    :param model_dim: rrn dimension size\n",
    "    :param mlp_dim: the dimension size of fully connected layer\n",
    "    :param mlp_depth: the depth of fully connected layers\n",
    "    :param drop_out: dropout rate of fully connected layers\n",
    "    :param return_customized_layers: boolean, default=False\n",
    "        If True, return model and customized object dictionary, otherwise return model only\n",
    "    :return: keras model\n",
    "    \"\"\"\n",
    "\n",
    "        # inputs\n",
    "    inputs1 = list()\n",
    "    for fi in range(num_channels1):\n",
    "        inputs1.append(models.Input(shape=(num_features1, feature_dim1), dtype='float32', name='input1_' + str(fi)))\n",
    "        \n",
    "    inputs2 = list()\n",
    "    for fi in range(num_channels2):\n",
    "        inputs2.append(models.Input(shape=(num_features2,), dtype='float32', name='input2_' + str(fi)))\n",
    "        \n",
    "    inputs3 = list()\n",
    "    for fi in range(num_channels3):\n",
    "        inputs3.append(models.Input(shape=(num_features3,), dtype='float32', name='input3_' + str(fi)))\n",
    "        \n",
    "    features1_pip = models.Sequential()\n",
    "    features1_pip.add(layers.TimeDistributed(layers.Dropout(rate=embed_dropout, name=\"embed_dropout_layer\")))\n",
    "    features1_pip.add(layers.TimeDistributed(layers.Dense(model_dim1, name=\"feature_map_layer1\", activation=\"relu\")))\n",
    "    features1_pip.add(layers.Flatten(name=\"embed_flatten_layer\"))\n",
    "    \n",
    "    features2_pip = models.Sequential()\n",
    "    features2_pip.add(layers.Dropout(rate=embed_dropout, name=\"dropout_layer2\"))\n",
    "    features2_pip.add(layers.Dense(model_dim2, name=\"feature_map_layer2\", activation=\"relu\"))\n",
    "    \n",
    "    features3_pip = models.Sequential()\n",
    "    features3_pip.add(layers.Dense(model_dim3, name=\"feature_map_layer3\", activation=\"relu\"))\n",
    "    \n",
    "    x1 = [features1_pip(input_) for input_ in inputs1]\n",
    "    x2 = [features2_pip(input_) for input_ in inputs2]\n",
    "    x3 = [features3_pip(input_) for input_ in inputs3]\n",
    "    \n",
    "    x = layers.Concatenate(axis=1, name=\"concate_layer\")(x1+x2+x3)\n",
    "    \n",
    "    # MLP Layers\n",
    "    x = layers.BatchNormalization(name='batch_norm_layer')(x)\n",
    "    x = layers.Dropout(rate=drop_out, name=\"dropout_layer\")(x)\n",
    "        \n",
    "    for i in range(mlp_depth - 1):\n",
    "        x = layers.Dense(mlp_dim, activation='selu', kernel_initializer='lecun_normal', name='selu_layer' + str(i))(x)\n",
    "        x = layers.AlphaDropout(drop_out, name='alpha_layer' + str(i))(x)\n",
    "\n",
    "    outputs = layers.Dense(output_dim, activation=\"softmax\", name=\"softmax_layer0\")(x)\n",
    "\n",
    "    model = models.Model(inputs1 + inputs2 + inputs3, outputs)\n",
    "\n",
    "    if return_customized_layers:\n",
    "        return model, {}\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fba6b5bd600789437a97bfafde4a68b76eaac03b"
   },
   "source": [
    "### Build Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "569aa2476fe1cf893ba878b5c83cc37713f2460a"
   },
   "outputs": [],
   "source": [
    "num_channels1 = 3\n",
    "num_channels2 = 3\n",
    "num_channels3 = 2\n",
    "num_features1 = p_emb_tra.shape[1]\n",
    "num_features2 = p_encode_tra.shape[1]\n",
    "#num_features2 = p_pos_tra.shape[1]\n",
    "num_features3 = pa_dist_tra.shape[1]\n",
    "feature_dim1 = p_emb_tra.shape[2]\n",
    "output_dim = 3\n",
    "mlp_dim = 60\n",
    "model_dim1 = 10\n",
    "model_dim2 = 10\n",
    "model_dim3 = 10\n",
    "mlp_depth=1\n",
    "embed_dropout=0.5\n",
    "drop_out=0.5\n",
    "return_customized_layers=True\n",
    "\n",
    "model, co = build_remap_mlp_model(\n",
    "    num_channels1, num_channels2, num_channels3, \n",
    "    num_features1, num_features2, num_features3, \n",
    "    feature_dim1, output_dim, model_dim1, model_dim2, model_dim3, mlp_dim, \n",
    "    mlp_depth=mlp_depth, embed_dropout=embed_dropout, drop_out=drop_out, \n",
    "    return_customized_layers=return_customized_layers\n",
    ")\n",
    "\n",
    "cos.append(co)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "13dc8379c35b5b5cf24ee5a32a7358b934ce56ce"
   },
   "outputs": [],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fd91fac5c5a6a233f87b04702893bbb7c00991d3"
   },
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "06a0d8ced3f0959cec05212bd5fa51f373aacd83"
   },
   "outputs": [],
   "source": [
    "adam = ko.Nadam()\n",
    "model.compile(adam, loss=\"sparse_categorical_crossentropy\", metrics=[\"sparse_categorical_accuracy\"])\n",
    "\n",
    "file_path = \"best_remap_mlp_model.hdf5\"\n",
    "check_point = kc.ModelCheckpoint(file_path, monitor = \"val_loss\", verbose = 1, save_best_only = True, mode = \"min\")\n",
    "early_stop = kc.EarlyStopping(monitor = \"val_loss\", mode = \"min\", patience=3)\n",
    "history = model.fit(X_train, y_tra, batch_size=20, epochs=20, validation_data=(X_dev, y_dev), callbacks = [check_point, early_stop])\n",
    "\n",
    "histories.append(np.min(np.asarray(history.history['val_loss'])))\n",
    "model_paths.append(file_path)\n",
    "\n",
    "del model, history\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8c6523f1ccf3ef9b05176b6b7f851faff180b0e9"
   },
   "source": [
    "## Multi-Channel CNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "998df73ae9a04d269039876194a880c45f6b36e3"
   },
   "outputs": [],
   "source": [
    "def build_multi_channel_cnn_model(\n",
    "    num_channels1, num_channels2, num_channels3, \n",
    "    num_features1, num_features2, num_features3, \n",
    "    feature_dim1, output_dim, model_dim1, model_dim2, model_dim3, mlp_dim, \n",
    "    num_filters, filter_sizes, padding, pooling,\n",
    "    mlp_depth=1, embed_dropout=0.5, drop_out=0.2, \n",
    "    return_customized_layers=False):\n",
    "    \"\"\"\n",
    "    Create A Multi-Layer Perceptron Model.\n",
    "    \n",
    "    inputs: \n",
    "        embeddings: [batch, num_embed_feature, embed_dims] * 3 ## pronoun, A, B\n",
    "        features: [batch, num_other_feature] * 3 ## pronoun, A, B\n",
    "        mention_pair_features: [batch, num_mention_pair_feature] * 2 ## pronoun-A, pronoun-B\n",
    "        \n",
    "    outputs: \n",
    "        [batch, num_classes] # in our case there should be 3 output classes: A, B, None\n",
    "        \n",
    "    :param output_dim: the output dimension size\n",
    "    :param model_dim: rrn dimension size\n",
    "    :param mlp_dim: the dimension size of fully connected layer\n",
    "    :param mlp_depth: the depth of fully connected layers\n",
    "    :param drop_out: dropout rate of fully connected layers\n",
    "    :param return_customized_layers: boolean, default=False\n",
    "        If True, return model and customized object dictionary, otherwise return model only\n",
    "    :return: keras model\n",
    "    \"\"\"\n",
    "\n",
    "    # inputs\n",
    "    inputs1 = list()\n",
    "    for fi in range(num_channels1):\n",
    "        inputs1.append(models.Input(shape=(num_features1, feature_dim1), dtype='float32', name='input1_' + str(fi)))\n",
    "        \n",
    "    inputs2 = list()\n",
    "    for fi in range(num_channels2):\n",
    "        inputs2.append(models.Input(shape=(num_features2,), dtype='float32', name='input2_' + str(fi)))\n",
    "        \n",
    "    inputs3 = list()\n",
    "    for fi in range(num_channels3):\n",
    "        inputs3.append(models.Input(shape=(num_features3,), dtype='float32', name='input3_' + str(fi)))\n",
    "        \n",
    "    features1_pip = models.Sequential()\n",
    "    features1_pip.add(layers.TimeDistributed(layers.Dropout(rate=embed_dropout, name=\"embed_dropout_layer\")))\n",
    "    features1_pip.add(layers.TimeDistributed(layers.Dense(model_dim1, name=\"feature_map_layer1\", activation=\"relu\")))\n",
    "    \n",
    "    features2_pip = models.Sequential()\n",
    "    features2_pip.add(layers.Dropout(rate=embed_dropout, name=\"dropout_layer2\"))\n",
    "    features2_pip.add(layers.Dense(model_dim2, name=\"feature_map_layer2\", activation=\"relu\"))\n",
    "    \n",
    "    features3_pip = models.Sequential()\n",
    "    features3_pip.add(layers.Dense(model_dim3, name=\"feature_map_layer3\", activation=\"relu\"))\n",
    "    \n",
    "    x1 = [features1_pip(input_) for input_ in inputs1]\n",
    "    x2 = [features2_pip(input_) for input_ in inputs2]\n",
    "    x3 = [features3_pip(input_) for input_ in inputs3]\n",
    "    \n",
    "    # cnn layers\n",
    "    cnns = []\n",
    "    for i in range(len(filter_sizes)):\n",
    "        cnns.append(models.Sequential())\n",
    "        cnns[-1].add(layers.Conv1D(num_filters[i], kernel_size=filter_sizes[i], padding=padding, activation='relu', name=\"cc_layer1\" + str(i)))\n",
    "        if pooling == 'max':\n",
    "            cnns[-1].add(layers.GlobalMaxPooling1D(name='global_pooling_layer' + str(i)))\n",
    "        else:\n",
    "            cnns[-1].add(layers.GlobalAveragePooling1D(name='global_pooling_layer' + str(i)))\n",
    "    \n",
    "    x1s = list()\n",
    "    for x1_ in x1:\n",
    "        x1s += [cnn_(x1_) for cnn_ in cnns]\n",
    "    x1 = x1s\n",
    "    \n",
    "    x = layers.Concatenate(axis=1, name=\"concate_layer\")(x1+x2+x3)\n",
    "    \n",
    "    # MLP Layers\n",
    "    x = layers.BatchNormalization(name='batch_norm_layer')(x)\n",
    "    x = layers.Dropout(rate=drop_out, name=\"dropout_layer\")(x)\n",
    "        \n",
    "    for i in range(mlp_depth - 1):\n",
    "        x = layers.Dense(mlp_dim, activation='selu', kernel_initializer='lecun_normal', name='selu_layer' + str(i))(x)\n",
    "        x = layers.AlphaDropout(drop_out, name='alpha_layer' + str(i))(x)\n",
    "\n",
    "    outputs = layers.Dense(output_dim, activation=\"softmax\", name=\"softmax_layer0\")(x)\n",
    "\n",
    "    model = models.Model(inputs1 + inputs2 + inputs3, outputs)\n",
    "\n",
    "    if return_customized_layers:\n",
    "        return model, {}\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "36ed7f737f689f2150a4796eab55059d0f31aef2"
   },
   "source": [
    "### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c76e572a0121902eb9d855949ed824dd6013a3bd"
   },
   "outputs": [],
   "source": [
    "num_channels1 = 3\n",
    "num_channels2 = 3\n",
    "num_channels3 = 2\n",
    "num_features1 = p_emb_tra.shape[1]\n",
    "num_features2 = p_encode_tra.shape[1]\n",
    "#num_features2 = p_pos_tra.shape[1]\n",
    "num_features3 = pa_dist_tra.shape[1]\n",
    "feature_dim1 = p_emb_tra.shape[2]\n",
    "output_dim = 3\n",
    "mlp_dim = 60\n",
    "model_dim1 = 10\n",
    "model_dim2 = 10\n",
    "model_dim3 = 10\n",
    "\n",
    "filter_sizes = [1, num_features1]\n",
    "num_filters = [5] * len(filter_sizes)\n",
    "pooling='max'\n",
    "padding='valid'\n",
    "\n",
    "mlp_depth=1\n",
    "embed_dropout=0.5\n",
    "drop_out=0.5\n",
    "return_customized_layers=True\n",
    "\n",
    "model, co = build_multi_channel_cnn_model(\n",
    "    num_channels1, num_channels2, num_channels3, \n",
    "    num_features1, num_features2, num_features3, \n",
    "    feature_dim1, output_dim, model_dim1, model_dim2, model_dim3, mlp_dim, \n",
    "    num_filters, filter_sizes, padding, pooling,\n",
    "    mlp_depth=mlp_depth, embed_dropout=embed_dropout, drop_out=drop_out, \n",
    "    return_customized_layers=return_customized_layers\n",
    ")\n",
    "\n",
    "cos.append(co)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "aab9555300c202aabd0a3e1ed23084bad624a9ac"
   },
   "outputs": [],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e6e3b24891f298ba9fd075973562e492f95a56ab"
   },
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a73d70bf362849c16ad30aa14527ab058cc676ea"
   },
   "outputs": [],
   "source": [
    "adam = ko.Nadam()\n",
    "model.compile(adam, loss=\"sparse_categorical_crossentropy\", metrics=[\"sparse_categorical_accuracy\"])\n",
    "\n",
    "file_path = \"best_mc_cnn_model.hdf5\"\n",
    "check_point = kc.ModelCheckpoint(file_path, monitor = \"val_loss\", verbose = 1, save_best_only = True, mode = \"min\")\n",
    "early_stop = kc.EarlyStopping(monitor = \"val_loss\", mode = \"min\", patience=3)\n",
    "history = model.fit(X_train, y_tra, batch_size=20, epochs=20, validation_data=(X_dev, y_dev), callbacks = [check_point, early_stop])\n",
    "\n",
    "histories.append(np.min(np.asarray(history.history['val_loss'])))\n",
    "model_paths.append(file_path)\n",
    "\n",
    "del model, history\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "00c9b579aa067775bd3790872d4c89c76e3d24d9"
   },
   "source": [
    "## Intra-Mention-Pair Coattention Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "da9b469cd8795644e1d1a8bb0986f466ec8f630e"
   },
   "outputs": [],
   "source": [
    "def build_intra_coattention_cnn_model(\n",
    "    num_channels1, num_channels2, num_channels3, \n",
    "    num_features1, num_features2, num_features3, \n",
    "    feature_dim1, output_dim, atten_dim, model_dim1, model_dim2, model_dim3, mlp_dim, \n",
    "    num_filters, filter_sizes, padding, pooling,\n",
    "    mlp_depth=1, embed_dropout=0.5, drop_out=0.2, \n",
    "    return_customized_layers=False):\n",
    "    \"\"\"\n",
    "    Create A Multi-Layer Perceptron Model with Coattention Mechanism.\n",
    "    \n",
    "    inputs: \n",
    "        embeddings: [batch, num_embed_feature, embed_dims] * 3 ## pronoun, A, B\n",
    "        positional_features: [batch, num_pos_feature] * 2 ## pronoun-A, pronoun-B\n",
    "        \n",
    "    outputs: \n",
    "        [batch, num_classes] # in our case there should be 3 output classes: A, B, None\n",
    "        \n",
    "    :param output_dim: the output dimension size\n",
    "    :param model_dim: rrn dimension size\n",
    "    :param mlp_dim: the dimension size of fully connected layer\n",
    "    :param mlp_depth: the depth of fully connected layers\n",
    "    :param drop_out: dropout rate of fully connected layers\n",
    "    :param return_customized_layers: boolean, default=False\n",
    "        If True, return model and customized object dictionary, otherwise return model only\n",
    "    :return: keras model\n",
    "    \"\"\"\n",
    "    \n",
    "    # inputs\n",
    "    inputs1 = list()\n",
    "    for fi in range(num_channels1):\n",
    "        inputs1.append(models.Input(shape=(num_features1, feature_dim1), dtype='float32', name='input1_' + str(fi)))\n",
    "        \n",
    "    inputs2 = list()\n",
    "    for fi in range(num_channels2):\n",
    "        inputs2.append(models.Input(shape=(num_features2,), dtype='float32', name='input2_' + str(fi)))\n",
    "        \n",
    "    inputs3 = list()\n",
    "    for fi in range(num_channels3):\n",
    "        inputs3.append(models.Input(shape=(num_features3,), dtype='float32', name='input3_' + str(fi)))\n",
    "        \n",
    "    features1_pip = models.Sequential()\n",
    "    features1_pip.add(layers.TimeDistributed(layers.Dropout(rate=embed_dropout, name=\"embed_dropout_layer\")))\n",
    "    \n",
    "    features2_pip = models.Sequential()\n",
    "    features2_pip.add(layers.Dropout(rate=embed_dropout, name=\"dropout_layer2\"))\n",
    "    features2_pip.add(layers.Dense(model_dim2, name=\"feature_map_layer2\", activation=\"relu\"))\n",
    "    \n",
    "    features3_pip = models.Sequential()\n",
    "    features3_pip.add(layers.Dense(model_dim3, name=\"feature_map_layer3\", activation=\"relu\"))\n",
    "    \n",
    "    x1 = [features1_pip(input_) for input_ in inputs1]\n",
    "    x2 = [features2_pip(input_) for input_ in inputs2]\n",
    "    x3 = [features3_pip(input_) for input_ in inputs3]\n",
    "    \n",
    "    # From mention-pair embeddings\n",
    "#     reshape_layer = layers.Reshape((1, feature_dim1), name=\"reshape_layer\")\n",
    "#     x2_ = [reshape_layer(x_) for x_ in x2]\n",
    "    \n",
    "    feature_concat_layer = layers.Concatenate(axis=1, name=\"concate_pair_layer\")\n",
    "    coatten_layer = RemappedCoAttentionWeight(atten_dim, name=\"coattention_weights_layer\")\n",
    "    featnorm_layer1 = FeatureNormalization(name=\"normalized_coattention_weights_layer1\", axis=1)\n",
    "    featnorm_layer2 = FeatureNormalization(name=\"normalized_coattention_weights_layer2\", axis=2)\n",
    "    focus_layer1 = layers.Dot((1, 1), name=\"focus_layer1\")\n",
    "    focus_layer2 = layers.Dot((2, 1), name=\"focus_layer2\")\n",
    "    pair_layer1 = layers.Concatenate(axis=-1, name=\"pair_layer1\")\n",
    "    pair_layer2 = layers.Concatenate(axis=-1, name=\"pair_layer2\")\n",
    "    \n",
    "    def coatten_compare(\n",
    "        feature_concat_layer, coatten_layer, \n",
    "        featnorm_layer1, featnorm_layer2, \n",
    "        focus_layer1, focus_layer2, \n",
    "        pair_layer1, pair_layer2, \n",
    "        mention1_x1, mention2_x1):\n",
    "        \n",
    "        _x1 = mention1_x1\n",
    "        _x2 = mention2_x1\n",
    "#         _x1 = feature_concat_layer([mention1_x1, mention1_x2])\n",
    "#         _x2 = feature_concat_layer([mention2_x1, mention2_x2])\n",
    "        \n",
    "        # attention\n",
    "        attens = coatten_layer([_x1, _x2])\n",
    "        attens1 = featnorm_layer1(attens)\n",
    "        attens2 = featnorm_layer2(attens)\n",
    "        # compare\n",
    "        focus1 = focus_layer1([attens1, _x1])\n",
    "        focus2 = focus_layer2([attens2, _x2])\n",
    "        _x1 = pair_layer1([_x1, focus2])\n",
    "        _x2 = pair_layer2([_x2, focus1])\n",
    "        \n",
    "        return _x1, _x2\n",
    "    \n",
    "    pairs = list()\n",
    "    pairs += list(coatten_compare(\n",
    "        feature_concat_layer, coatten_layer,\n",
    "        featnorm_layer1, featnorm_layer2, \n",
    "        focus_layer1, focus_layer2, \n",
    "        pair_layer1, pair_layer2, \n",
    "        x1[0], x1[1]))\n",
    "    pairs += list(coatten_compare(\n",
    "        feature_concat_layer, coatten_layer,\n",
    "        featnorm_layer1, featnorm_layer2, \n",
    "        focus_layer1, focus_layer2, \n",
    "        pair_layer1, pair_layer2, \n",
    "        x1[0], x1[2]))\n",
    "    \n",
    "#     x1 = layers.Concatenate(axis=1, name=\"atten_concate_layer\")(pairs)\n",
    "#     x1 = layers.TimeDistributed(layers.Dropout(rate=drop_out, name=\"pair_dropout_layer\"))(x1)\n",
    "#     x1 = layers.TimeDistributed(layers.Dense(model_dim1, name=\"pair_feature_map_layer\", activation=\"relu\"))(x1)\n",
    "#     x1 = layers.Flatten(name=\"pair_feature_flatten_layer1\")(x1)\n",
    "\n",
    "    # cnn layers\n",
    "    cnns = []\n",
    "    for i in range(len(filter_sizes)):\n",
    "        cnns.append(models.Sequential())\n",
    "        cnns[-1].add(layers.Conv1D(num_filters[i], kernel_size=filter_sizes[i], padding=padding, activation='relu', name=\"cc_layer1\" + str(i)))\n",
    "        if pooling == 'max':\n",
    "            cnns[-1].add(layers.GlobalMaxPooling1D(name='global_pooling_layer' + str(i)))\n",
    "        else:\n",
    "            cnns[-1].add(layers.GlobalAveragePooling1D(name='global_pooling_layer' + str(i)))\n",
    "    \n",
    "    x1 = layers.Concatenate(axis=1, name=\"cnn_concate_layer\")(pairs)\n",
    "    x1 = layers.TimeDistributed(layers.Dropout(rate=drop_out, name=\"pair_dropout_layer\"))(x1)\n",
    "    x1 = [cnn_(x1) for cnn_ in cnns]\n",
    "    \n",
    "    x = layers.Concatenate(axis=1, name=\"concate_layer\")(x1+x2+x3)\n",
    "    \n",
    "    # MLP Layers\n",
    "    x = layers.BatchNormalization(name='batch_norm_layer')(x)\n",
    "    x = layers.Dropout(rate=drop_out, name=\"dropout_layer\")(x)\n",
    "        \n",
    "    for i in range(mlp_depth - 1):\n",
    "        x = layers.Dense(mlp_dim, activation='selu', kernel_initializer='lecun_normal', name='selu_layer' + str(i))(x)\n",
    "        x = layers.AlphaDropout(drop_out, name='alpha_layer' + str(i))(x)\n",
    "\n",
    "    outputs = layers.Dense(output_dim, activation=\"softmax\", name=\"softmax_layer0\")(x)\n",
    "    \n",
    "    model = models.Model(inputs1 + inputs2 + inputs3, outputs)\n",
    "\n",
    "    if return_customized_layers:\n",
    "        return model, {'RemappedCoAttentionWeight': RemappedCoAttentionWeight,\n",
    "                       \"FeatureNormalization\": FeatureNormalization}\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d76f495a534d482070c7b0f186d3bf49a5c749e7"
   },
   "source": [
    "### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b2205088e1a863a991931d4ccb10a75be86b8ed9"
   },
   "outputs": [],
   "source": [
    "num_channels1 = 3\n",
    "num_channels2 = 3\n",
    "num_channels3 = 2\n",
    "num_features1 = p_emb_tra.shape[1]\n",
    "num_features2 = p_encode_tra.shape[1]\n",
    "#num_features2 = p_pos_tra.shape[1]\n",
    "num_features3 = pa_dist_tra.shape[1]\n",
    "feature_dim1 = p_emb_tra.shape[2]\n",
    "output_dim = 3\n",
    "mlp_dim = 60\n",
    "atten_dim = 10\n",
    "model_dim1 = 2\n",
    "model_dim2 = 10\n",
    "model_dim3 = 10\n",
    "\n",
    "filter_sizes = [1]\n",
    "num_filters = [10] * len(filter_sizes)\n",
    "pooling='average'\n",
    "padding='valid'\n",
    "\n",
    "mlp_depth=1\n",
    "embed_dropout=0.5\n",
    "drop_out=0.5\n",
    "return_customized_layers=True\n",
    "\n",
    "model, co = build_intra_coattention_cnn_model(\n",
    "    num_channels1, num_channels2, num_channels3, \n",
    "    num_features1, num_features2, num_features3, \n",
    "    feature_dim1, output_dim, atten_dim, model_dim1, model_dim2, model_dim3, mlp_dim, \n",
    "    num_filters, filter_sizes, padding, pooling,\n",
    "    mlp_depth=mlp_depth, embed_dropout=embed_dropout, drop_out=drop_out, \n",
    "    return_customized_layers=return_customized_layers\n",
    ")\n",
    "\n",
    "cos.append(co)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "19bdf0ff3437f39910463329d0aa2effa110f579"
   },
   "outputs": [],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "760912bfa6ee6edcfe5d45fbb0db49f99e1266ba"
   },
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3c1434deb08877a3f8bee9ce77235e2f63885dbe"
   },
   "outputs": [],
   "source": [
    "adam = ko.Nadam()\n",
    "model.compile(adam, loss=\"sparse_categorical_crossentropy\", metrics=[\"sparse_categorical_accuracy\"])\n",
    "\n",
    "file_path = \"best_intra_coatt_cnn_model.hdf5\"\n",
    "check_point = kc.ModelCheckpoint(file_path, monitor = \"val_loss\", verbose = 1, save_best_only = True, mode = \"min\")\n",
    "early_stop = kc.EarlyStopping(monitor = \"val_loss\", mode = \"min\", patience=3)\n",
    "history = model.fit(X_train, y_tra, batch_size=30, epochs=40, validation_data=(X_dev, y_dev), callbacks = [check_point, early_stop])\n",
    "\n",
    "histories.append(np.min(np.asarray(history.history['val_loss'])))\n",
    "model_paths.append(file_path)\n",
    "\n",
    "del model, history\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8bb147615d4920a2f3500a0fba12d31cb0869304"
   },
   "source": [
    "###  Make Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "79cb8d339da04ad2d52e3675a4295f55a6ccd148"
   },
   "outputs": [],
   "source": [
    "print(\"load best model: \" + str(model_paths[np.argmin(histories)]))\n",
    "model = models.load_model(\n",
    "    model_paths[np.argmin(histories)], cos[np.argmin(histories)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4c465342c3a99a4996a104fdb00ceab4e85b9649"
   },
   "outputs": [],
   "source": [
    "print(\"load best model: \" + str(model_paths[2]))\n",
    "model = models.load_model(\n",
    "    model_paths[2], cos[2])\n",
    "y_preds = model.predict(X_test, batch_size = 1024, verbose = 1)\n",
    "\n",
    "sub_df_path = os.path.join(SUB_DATA_FOLDER, 'sample_submission_stage_1.csv')\n",
    "sub_df = pd.read_csv(sub_df_path)\n",
    "sub_df.loc[:, 'A'] = pd.Series(y_preds[:, 0])\n",
    "sub_df.loc[:, 'B'] = pd.Series(y_preds[:, 1])\n",
    "sub_df.loc[:, 'NEITHER'] = pd.Series(y_preds[:, 2])\n",
    "\n",
    "sub_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3287b186f7b54b4986585384a5678c97cd0f2405"
   },
   "source": [
    "# Measure Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics as skm\n",
    "from keras import activations, constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_log_loss(ground, preds):\n",
    "    preds = preds.tolist()\n",
    "    return skm.log_loss(ground, preds, labels=[0, 1, 2], eps=10**-15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-b7e211f8abde>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeasure_log_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'y_test' is not defined"
     ]
    }
   ],
   "source": [
    "print(measure_log_loss(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import differential_evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'models' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-07ec1591dbd1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_paths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     model = models.load_model(\n\u001b[0m\u001b[1;32m      7\u001b[0m         model_path, cos[i])\n\u001b[1;32m      8\u001b[0m     \u001b[0my_dev_preds_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_dev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'models' is not defined"
     ]
    }
   ],
   "source": [
    "y_dev_preds_list = list()\n",
    "y_test_preds_list = list()\n",
    "\n",
    "for i in range(0, len(model_paths)):\n",
    "    model_path = model_paths[i]\n",
    "    model = models.load_model(\n",
    "        model_path, cos[i])\n",
    "    y_dev_preds_list.append(model.predict(X_dev, batch_size = 1024, verbose = 1))\n",
    "    y_test_preds_list.append(model.predict(X_test, batch_size = 1024, verbose = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lo = 0\n",
    "hi = len(y_dev_preds_list) - 1\n",
    "y_dev_preds_list1 = y_dev_preds_list[lo:hi]\n",
    "y_test_preds_list1 = y_test_preds_list[lo:hi]\n",
    "\n",
    "len(y_test_preds_list1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = None\n",
    "\n",
    "num_models = 0\n",
    "for i in range(lo, hi):\n",
    "    y_preds_ = y_test_preds_list[i]\n",
    "    \n",
    "    if y_preds is None:\n",
    "        y_preds = y_preds_\n",
    "    else:\n",
    "        y_preds += y_preds_\n",
    "    \n",
    "    num_models += 1\n",
    "\n",
    "y_preds /= num_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(measure_log_loss(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weighted Average By Stochastic Global Search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize a vector to have unit norm\n",
    "def normalize(weights):\n",
    "    # calculate l1 vector norm\n",
    "    #print(weights.shape)\n",
    "    result = np.linalg.norm(weights, 1)\n",
    "    # check for a vector of all zeros\n",
    "    if result == 0.0:\n",
    "        return weights\n",
    "    # return normalized vector (unit norm)\n",
    "    return weights / result\n",
    "\n",
    "def wa_model(weights, X_meta_list):\n",
    "    # normalize weights\n",
    "    normalized = normalize(weights)\n",
    "    \n",
    "    X_meta = np.array(X_meta_list)\n",
    "    # weighted sum across ensemble members\n",
    "    summed = np.tensordot(X_meta, normalized, axes=((0),(0)))\n",
    "    return summed\n",
    "    \n",
    "def loss_function(weights, X_meta_list, y):\n",
    "    y_pred_ = wa_model(weights, X_meta_list)\n",
    "    \n",
    "    return measure_log_loss(y, y_pred_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble(X_meta_list, y, X_test_meta_list):\n",
    "    # define bounds on each weight\n",
    "    bound_w = [(0.0, 1.0)  for _ in range(hi-lo)]\n",
    "    # arguments to the loss function\n",
    "    search_arg = (X_meta_list, y)\n",
    "    # global optimization of ensemble weights\n",
    "    weights = differential_evolution(loss_function, bound_w, search_arg, maxiter=1000, tol=1e-7)['x']\n",
    "    \n",
    "    print(normalize(weights))\n",
    "    \n",
    "    return wa_model(weights, X_test_meta_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = ensemble(y_dev_preds_list1, y_dev, y_test_preds_list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(measure_log_loss(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weighted Average By Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightedAverage(Layer):\n",
    "\n",
    "    def __init__(self,**kwargs):\n",
    "\n",
    "        self.supports_masking = False\n",
    "        self.init = initializers.get('lecun_normal')\n",
    "        \n",
    "        self.w_regularizer = regularizers.get(None)\n",
    "        self.w_constraint = constraints.get(None)\n",
    "        \n",
    "        super(WeightedAverage, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "\n",
    "        self.w = self.add_weight((input_shape[1], ),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_ww'.format(self.name),\n",
    "                                 regularizer=self.w_regularizer,\n",
    "                                 constraint=self.w_constraint)\n",
    "\n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        # do not pass the mask to the next layers\n",
    "        return None\n",
    "\n",
    "    def call(self, inputs, mask=None):\n",
    "        x = inputs\n",
    "        \n",
    "        w = activations.sigmoid(self.w)\n",
    "        w = w / (K.sum(w) + K.epsilon())\n",
    "        w = K.expand_dims(w)\n",
    "        print(w.shape)\n",
    "        weighted_input = x * w\n",
    "        return K.sum(weighted_input, axis=1)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0], input_shape[-1]\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "        }\n",
    "        base_config = super(WeightedAverage, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_ensemble_model(num_models, input_dims, output_dims):\n",
    "    \n",
    "    # inputs\n",
    "    inputs = models.Input(shape=(num_models, input_dims), dtype='float32', name='input')\n",
    "    \n",
    "    x = inputs\n",
    "    \n",
    "    outputs = WeightedAverage(name=\"softmax_layer\")(x)\n",
    "    \n",
    "    model = models.Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble(X_meta_list, y, X_test_meta_list):\n",
    "    en_model = build_ensemble_model(hi-lo, 3, 3)\n",
    "    adam = ko.Adam(lr=0.001)\n",
    "    early_stop = kc.EarlyStopping(monitor = \"loss\", mode = \"min\", patience=5)\n",
    "    en_model.compile(adam, loss=\"sparse_categorical_crossentropy\", metrics=[\"sparse_categorical_accuracy\"])\n",
    "    \n",
    "    print(en_model.summary())\n",
    "\n",
    "    X_ = np.stack(X_meta_list, axis=1)\n",
    "    X_test_ = np.stack(X_test_meta_list, axis=1)\n",
    "    \n",
    "    en_model.fit(X_, y, batch_size=10000, epochs=300, callbacks = [early_stop])\n",
    "    \n",
    "    return en_model.predict(X_test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = ensemble(y_test_preds_list1, y_test, y_test_preds_list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(measure_log_loss(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df_path = os.path.join(SUB_DATA_FOLDER, 'sample_submission_stage_1.csv')\n",
    "sub_df = pd.read_csv(sub_df_path)\n",
    "sub_df.loc[:, 'A'] = pd.Series(y_preds[:, 0])\n",
    "sub_df.loc[:, 'B'] = pd.Series(y_preds[:, 1])\n",
    "sub_df.loc[:, 'NEITHER'] = pd.Series(y_preds[:, 2])\n",
    "\n",
    "sub_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6cfa1933801af3de8d5d6cfc1cd9c3e23481e0bd"
   },
   "outputs": [],
   "source": [
    "sub_df.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
