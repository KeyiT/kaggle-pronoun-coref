{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gap-coreference', 'gendered-pronoun-resolution', 'gap-data']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "import zipfile\n",
    "import sys\n",
    "import time\n",
    "import gc\n",
    "import json\n",
    "from tempfile import TemporaryFile\n",
    "\n",
    "import seaborn as sns\n",
    "import spacy\n",
    "from sklearn import metrics as skm\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "86ef0e07d7811dad271acf0b0fe7b90867eaada2"
   },
   "source": [
    " # Data Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "a98de88f7a982ba72a389122c0a5006a5392da37"
   },
   "outputs": [],
   "source": [
    "DATA_ROOT = '../input/'\n",
    "GAP_DATA_FOLDER = os.path.join(DATA_ROOT, 'gap-data')\n",
    "\n",
    "df_path1 = os.path.join(GAP_DATA_FOLDER, 'gap-phase1.csv')\n",
    "df_path2 = os.path.join(GAP_DATA_FOLDER, 'gap-phase2.csv')\n",
    "\n",
    "df = pd.read_csv(df_path1)\n",
    "test_df = pd.read_csv(df_path2)\n",
    "\n",
    "# split development data\n",
    "dev_size = 454\n",
    "dev_df = df.iloc[:dev_size]\n",
    "train_df = df.iloc[dev_size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "252d2ea9dcf984fed9d02bce0e90ded5823b14f2"
   },
   "source": [
    "# Clean Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "eb848940ddd8189fae9187c781c40b68b028092a"
   },
   "source": [
    "# Clip Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "54eb76b017c8623aaa809f64e0335ca0a49f4c8c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/scipy/stats/stats.py:1713: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f96feec9320>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(train_df['Text'].map(lambda ele: len(ele.split(\" \"))), kde_kws={\"label\": \"text\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1fcf1110b6b31cd65cc1dec7c3c730f83036c629"
   },
   "source": [
    "Set max length to 150 covers most of cases. Clip text where the token length longer than 150."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "096666b7ecea234422d085a9ee95d40f85bb333b"
   },
   "outputs": [],
   "source": [
    "MAX_LEN = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "461763372b5e807f349b8467bc205a7f5d98f6e9"
   },
   "outputs": [],
   "source": [
    "def bs(list_, target_):\n",
    "    lo, hi = 0, len(list_) -1\n",
    "    \n",
    "    while lo < hi:\n",
    "        mid = lo + int((hi - lo) / 2)\n",
    "        \n",
    "        if target_ < list_[mid]:\n",
    "            hi = mid\n",
    "        elif target_ > list_[mid]:\n",
    "            lo = mid + 1\n",
    "        else:\n",
    "            return mid + 1\n",
    "    return lo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "28ac8b7602efbe080c87babe0e22d7cf5b573e32"
   },
   "outputs": [],
   "source": [
    "def clip_text(text, max_len, char_offset_p, char_offset_a, char_offset_b):\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    if len(doc) <= max_len:\n",
    "        return text, 0\n",
    "    \n",
    "    token_lens = [token.idx for token in doc]\n",
    "    char_offset_min = min(char_offset_p, char_offset_a, char_offset_b)\n",
    "    char_offset_max = max(char_offset_p, char_offset_a, char_offset_b)\n",
    "    \n",
    "    # char offset to token offset\n",
    "    mention_offset_min = bs(token_lens, char_offset_min) - 1\n",
    "    mention_offset_max = bs(token_lens, char_offset_max) - 1\n",
    "    \n",
    "    if mention_offset_max - mention_offset_min + 1 > max_len:\n",
    "        raise ValueError\n",
    "    \n",
    "    # make sure the mention is in the sentence span\n",
    "    if mention_offset_max < max_len-1:\n",
    "        hi = doc[max_len].idx\n",
    "        return text[0:hi].strip(), 0\n",
    "    else:\n",
    "        len_span = mention_offset_max - mention_offset_min + 1\n",
    "        hi_idx = min(int((max_len - len_span) / 2 + mention_offset_max + 1), len(doc))\n",
    "        lo_idx = hi_idx - max_len\n",
    "        text_append = text + \" \"\n",
    "        return text_append[doc[lo_idx].idx: doc[hi_idx-1].idx + (doc[hi_idx-1].idx + len(doc[hi_idx-1]))].strip(), doc[lo_idx].idx\n",
    "    \n",
    "def text_clip_func(row, max_len):\n",
    "    text, shift = clip_text(row['Text'], max_len, row['Pronoun-offset'], row['A-offset'], row['B-offset'])\n",
    "    return pd.Series([text, shift], index=['Text', 'Shift'])\n",
    "\n",
    "def text_clip_update(df, max_len):\n",
    "    clip_info = df.apply(lambda row: text_clip_func(row, MAX_LEN), axis=1)\n",
    "    df['Text'] = clip_info['Text']\n",
    "    df['Pronoun-offset'] = df['Pronoun-offset'] - clip_info['Shift']\n",
    "    df['A-offset'] = df['A-offset'] - clip_info['Shift']\n",
    "    df['B-offset'] = df['B-offset'] - clip_info['Shift']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "11abe2504b525c68ecc3faa820c7e2a96f1c4f2d"
   },
   "source": [
    "# Encode By BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "26e811daa96d51bacaab58df081330063db24a2e"
   },
   "source": [
    "Downloading the pre-trained BERT -Base, Uncased model. The kernel needs an Internet connection to do this, so make sure it's enabled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-04-08 02:41:06--  https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-24_H-1024_A-16.zip\r\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.142.128, 2607:f8b0:400e:c08::80\r\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.142.128|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 1247797031 (1.2G) [application/zip]\r\n",
      "Saving to: ‘uncased_L-24_H-1024_A-16.zip’\r\n",
      "\r\n",
      "uncased_L-24_H-1024 100%[===================>]   1.16G  60.6MB/s    in 18s     \r\n",
      "\r\n",
      "2019-04-08 02:41:24 (67.3 MB/s) - ‘uncased_L-24_H-1024_A-16.zip’ saved [1247797031/1247797031]\r\n",
      "\r\n",
      "bert_config.json\t\t     bert_model.ckpt.index  vocab.txt\r\n",
      "bert_model.ckpt.data-00000-of-00001  bert_model.ckpt.meta\r\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#downloading weights and cofiguration file for the model\n",
    "!wget https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-24_H-1024_A-16.zip\n",
    "with zipfile.ZipFile(\"uncased_L-24_H-1024_A-16.zip\",\"r\") as zip_ref:\n",
    "    zip_ref.extractall()\n",
    "!ls 'uncased_L-24_H-1024_A-16'\n",
    "os.system(\"rm \" + \"uncased_L-24_H-1024_A-16.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "632a8531b58804cd28272c2ef8dd5b5102334bd7"
   },
   "source": [
    "Next, in order to feed our data to the model, we'll use some scripts from the bert repo on GitHub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "3e0ac6bb63d1487866640ebe8e73f78b3a96c25a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-04-08 02:41:45--  https://raw.githubusercontent.com/google-research/bert/master/modeling.py\r\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\r\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 37922 (37K) [text/plain]\r\n",
      "Saving to: ‘modeling.py’\r\n",
      "\r\n",
      "modeling.py         100%[===================>]  37.03K  --.-KB/s    in 0.007s  \r\n",
      "\r\n",
      "2019-04-08 02:41:45 (4.95 MB/s) - ‘modeling.py’ saved [37922/37922]\r\n",
      "\r\n",
      "--2019-04-08 02:41:46--  https://raw.githubusercontent.com/google-research/bert/master/extract_features.py\r\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\r\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 13898 (14K) [text/plain]\r\n",
      "Saving to: ‘extract_features.py’\r\n",
      "\r\n",
      "extract_features.py 100%[===================>]  13.57K  --.-KB/s    in 0.007s  \r\n",
      "\r\n",
      "2019-04-08 02:41:46 (1.94 MB/s) - ‘extract_features.py’ saved [13898/13898]\r\n",
      "\r\n",
      "--2019-04-08 02:41:46--  https://raw.githubusercontent.com/google-research/bert/master/tokenization.py\r\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\r\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 12257 (12K) [text/plain]\r\n",
      "Saving to: ‘tokenization.py’\r\n",
      "\r\n",
      "tokenization.py     100%[===================>]  11.97K  --.-KB/s    in 0s      \r\n",
      "\r\n",
      "2019-04-08 02:41:47 (79.1 MB/s) - ‘tokenization.py’ saved [12257/12257]\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/google-research/bert/master/modeling.py \n",
    "!wget https://raw.githubusercontent.com/google-research/bert/master/extract_features.py \n",
    "!wget https://raw.githubusercontent.com/google-research/bert/master/tokenization.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "cfccbec6c87185a0db428e3ce8ecb93aa9c4547e"
   },
   "outputs": [],
   "source": [
    "import modeling\n",
    "import extract_features\n",
    "import tokenization\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f525be88f8fa80c8a8b680c0946e111cd7f653fa"
   },
   "source": [
    "Next, we feed BERT the data from these three files. For each line, we want to obtain contextual embeddings for the 3 target words (A, B, Pronoun). Here are some helper functions to keep track of the offsets of the target words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "1a655a90d41802605da6f27c605313eac4af4cc2"
   },
   "outputs": [],
   "source": [
    "def compute_offset_no_spaces(text, offset):\n",
    "    text_ = text[:offset]\n",
    "    text_ = text_.replace(\" \", \"\")\n",
    "    return len(text_)\n",
    "\n",
    "def count_length_no_special(text):\n",
    "    special_char_list = [\"#\", \" \"]\n",
    "    text_ = str(text)\n",
    "    for char_ in special_char_list:\n",
    "        text_ = text_.replace(char_, \"\")\n",
    "    return len(text_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6552a7a9786187610be695fcf25766594ca41685"
   },
   "source": [
    "The following method takes the data from a file, passes it through BERT to obtain contextual embeddings for the target words, then returns these embeddings in the emb DataFrame. Below, we will use it 3 times, once for each of the files gap-test, gap-development, gap-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "b3e8d15ba8b412108f531837a17b872eda061b92"
   },
   "outputs": [],
   "source": [
    "NUM_BERT_LAYERS = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "a87918b4b7571aed01741a614462d42805fa5b98"
   },
   "outputs": [],
   "source": [
    "def batch_file_path(dst_folder, dataset_name, batch_index, file_format):\n",
    "    return dst_folder + \"/\" + dataset_name + '_' + str(batch_index) + file_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "9d8437cb4f7c1737e0c915d7d16cc3d004612416"
   },
   "outputs": [],
   "source": [
    "def encode_by_bert_batch(data, embed_file_name, dst_folder, dataset_name, batch_index):\n",
    "    '''\n",
    "    Runs a forward propagation of BERT on input text, extracting contextual word embeddings\n",
    "    Input: data, a pandas DataFrame containing the information in one of the GAP files\n",
    "\n",
    "    Output: emb, a pandas DataFrame containing contextual embeddings for the words A, B and Pronoun. Each embedding is a numpy array of shape (768)\n",
    "    columns: \"emb_A\": the embedding for word A\n",
    "             \"emb_B\": the embedding for word B\n",
    "             \"emb_P\": the embedding for the pronoun\n",
    "             \"label\": the answer to the coreference problem: \"A\", \"B\" or \"NEITHER\"\n",
    "    '''\n",
    "    # From the current file, take the text only, and write it in a file which will be passed to BERT\n",
    "    data[\"Text\"].to_csv(\"input.txt\", index=False, header=False)\n",
    "    # The script extract_features.py runs forward propagation through BERT, and writes the output in the file output.jsonl\n",
    "    # I'm lazy, so I'm only saving the output of the last layer. Feel free to change --layers = -1 to save the output of other layers.\n",
    "    os.system(\"python3 extract_features.py \\\n",
    "      --input_file=input.txt \\\n",
    "      --output_file=\" + embed_file_name + \" \\\n",
    "      --vocab_file=uncased_L-24_H-1024_A-16/vocab.txt \\\n",
    "      --bert_config_file=uncased_L-24_H-1024_A-16/bert_config.json \\\n",
    "      --init_checkpoint=uncased_L-24_H-1024_A-16/bert_model.ckpt \\\n",
    "      --layers=-13,-14,-15,-16,-17,-18\\\n",
    "      --max_seq_length=\" + str(int(MAX_LEN*1.6)) + \" \\\n",
    "      --batch_size=8\")\n",
    "    os.system(\"rm input.txt\")\n",
    "    \n",
    "    print(batch_index)\n",
    "    bert_output = pd.read_json(embed_file_name, lines=True)\n",
    "\n",
    "    index = data.index\n",
    "    columns = [\"emb_A\", \"emb_B\", \"emb_P\", \"label\"]\n",
    "\n",
    "    rdata = np.zeros(shape=(len(data), 3))\n",
    "    # save embedding file\n",
    "    batch_matrix = list()\n",
    "    for i in range(len(data)):  # For each line in the data file\n",
    "\n",
    "        # For each word, find the offset not counting spaces. This is necessary for comparison with the output of BERT\n",
    "        P_offset = compute_offset_no_spaces(data.iloc[i][\"Text\"], data.iloc[i][\"Pronoun-offset\"])\n",
    "        A_offset = compute_offset_no_spaces(data.iloc[i][\"Text\"], data.iloc[i][\"A-offset\"])\n",
    "        B_offset = compute_offset_no_spaces(data.iloc[i][\"Text\"], data.iloc[i][\"B-offset\"])\n",
    "\n",
    "        # Initialize counts\n",
    "        count_chars = 0\n",
    "\n",
    "        # find token index for P A and B\n",
    "        features = bert_output.iloc[i][\"features\"]  # Get the BERT embeddings for the current line in the data file\n",
    "        times_to_try = 7\n",
    "        p_embds, a_embds, b_embds = None, None, None\n",
    "        \n",
    "        for j in range(2 if features[1][\"token\"] == \"\\\"\" else 1, len(features)):  # Iterate over the BERT  tokens for the current line; we skip over the first 2 tokens, which don't correspond to words\n",
    "            token = features[j][\"token\"]\n",
    "\n",
    "            # See if the character count until the current token matches the offset of any of the 3 target words\n",
    "            if count_chars >= P_offset and p_embds is None:\n",
    "                found = False\n",
    "                for tt in range(times_to_try):\n",
    "                    if features[max(0, j - tt)][\"token\"].lower().strip() == data.iloc[i]['Pronoun'].lower().strip():\n",
    "                        rdata[i, 0] = max(0, j - tt)\n",
    "                        found = True\n",
    "                        break\n",
    "                if not found:\n",
    "                    for tt in range(times_to_try - 1):\n",
    "                        if features[min(len(features) - 1, j + tt + 1)][\"token\"].lower().strip() == data.iloc[i]['Pronoun'].lower().strip():\n",
    "                            rdata[i, 0] = min(len(features) - 1, j + tt + 1)\n",
    "                            found = True\n",
    "                            break\n",
    "                if not found:\n",
    "                    print(\"TOKEN NOT FOUND!\")\n",
    "                    print(features[max(0, j - times_to_try): min(len(features) - 1, j + times_to_try)][\"token\"])\n",
    "                    print(data.iloc[i]['Pronoun'])\n",
    "                    print(data.iloc[i]['Text'])\n",
    "                    print()\n",
    "                \n",
    "                p_embds = [\n",
    "                    layer_json['values']  for layer_json in features[int(rdata[i, 0])][\"layers\"]\n",
    "                ]\n",
    "\n",
    "            if count_chars >= A_offset and a_embds is None:\n",
    "                found = False\n",
    "                for tt in range(times_to_try):\n",
    "                    if features[max(0, j - tt)][\"token\"].lower().strip() == data.iloc[i]['A'].lower().strip():\n",
    "                        rdata[i, 1] = max(0, j - tt)\n",
    "                        found = True\n",
    "                        break\n",
    "                if not found:\n",
    "                    for tt in range(times_to_try - 1):\n",
    "                        if features[min(len(features) - 1, j + tt + 1)][\"token\"].lower().strip() == data.iloc[i]['A'].lower().strip():\n",
    "                            rdata[i, 1] = min(len(features) - 1, j + tt + 1)\n",
    "                            found = True\n",
    "                            break\n",
    "                if not found:\n",
    "                    print(\"TOKEN NOT FOUND!\")\n",
    "                    print(features[max(0, j - times_to_try):min(len(features) - 1, j + times_to_try)][\"token\"])\n",
    "                    print(data.iloc[i]['A'])\n",
    "                    print(data.iloc[i]['Text'])\n",
    "                    print()\n",
    "                    \n",
    "                a_embds = [\n",
    "                    layer_json['values']  for layer_json in features[int(rdata[i, 1])][\"layers\"]\n",
    "                ]\n",
    "                    \n",
    "            if count_chars >= B_offset and b_embds is None:\n",
    "                found = False\n",
    "                for tt in range(times_to_try):\n",
    "                    if features[max(0, j - tt)][\"token\"].lower().strip() == data.iloc[i]['B'].lower().strip():\n",
    "                        rdata[i, 2] = max(0, j - tt)\n",
    "                        found = True\n",
    "                        break\n",
    "                if not found:\n",
    "                    for tt in range(times_to_try - 1):\n",
    "                        if features[min(len(features) - 1, j + tt + 1)][\"token\"].lower().strip() == data.iloc[i]['B'].lower().strip():\n",
    "                            rdata[i, 2] = min(len(features) - 1, j + tt + 1)\n",
    "                            found = True\n",
    "                            break\n",
    "                if not found:\n",
    "                    print(\"TOKEN NOT FOUND!\")\n",
    "                    print(features[max(0, j - times_to_try):min(len(features) - 1, j + times_to_try)][\"token\"])\n",
    "                    print(data.iloc[i]['B'])\n",
    "                    print(data.iloc[i]['Text'])\n",
    "                    print()\n",
    "                \n",
    "                b_embds = [\n",
    "                    layer_json['values']  for layer_json in features[int(rdata[i, 2])][\"layers\"]\n",
    "                ]\n",
    "            # Update the character count\n",
    "            count_chars += count_length_no_special(token)\n",
    "            \n",
    "        if p_embds is None or a_embds is None or b_embds is None:\n",
    "            print(count_chars)\n",
    "            print(P_offset)\n",
    "            print(A_offset)\n",
    "            print(B_offset)\n",
    "            print(data.iloc[i][\"Text\"])\n",
    "            print([features[j]['token'] for j in range(2, len(features))])\n",
    "            raise ValueError()\n",
    "            \n",
    "        batch_matrix.append([p_embds, a_embds, b_embds])\n",
    "        p_embds, a_embds, b_embds = None, None, None\n",
    "            \n",
    "    batch_matrix = np.asarray(batch_matrix)\n",
    "    np.save(batch_file_path(dst_folder, dataset_name, batch_index, \".npy\"), batch_matrix)\n",
    "        \n",
    "    os.system(\"rm \" + embed_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "ef78b0e41e6fbd35f756e4ac672f532f001d68e8"
   },
   "outputs": [],
   "source": [
    "def encode_by_bert(data_df, batch_size, embed_file_name, dst_folder, dataset_name):\n",
    "    num_batches = int(np.ceil(float(data_df.shape[0]) / batch_size))\n",
    "    print('num batches:' + str(num_batches))\n",
    "        \n",
    "    for batch_index in range(num_batches):\n",
    "        data_batch = data_df.iloc[batch_index * batch_size: min(batch_index * batch_size + batch_size, data_df.shape[0])]\n",
    "        if data_batch.shape[0] == 0:\n",
    "            break\n",
    "        encode_by_bert_batch(data_batch, embed_file_name, dst_folder, dataset_name, batch_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "98ca59d6fc859477aff649ea2ca8a35f65201e9d"
   },
   "source": [
    "# Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "e93689d2877fdab7c3bcf994dbae35aeae0a62ff"
   },
   "outputs": [],
   "source": [
    "! mkdir embs\n",
    "embed_folder = \"embs\"\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm', disable=['tagger', 'ner', 'textcat'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8fc498420e4780c67877071a69aec86cf7f993d6"
   },
   "source": [
    "### Running Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "2f1f3bc852afbcbf898ee6f95cba76dc49c19fc4"
   },
   "outputs": [],
   "source": [
    "# pd.options.display.max_colwidth = 1000\n",
    "\n",
    "# dev_df = pd.read_csv(dev_df_path, sep='\\t').drop(columns=['URL',])\n",
    "# # clean text\n",
    "# dev_df_ = dev_df.apply(entity_replace_func, axis=1)\n",
    "# # clip text\n",
    "# text_clip_update(dev_df_, MAX_LEN)\n",
    "\n",
    "# for i in range(dev_df_.shape[0]):\n",
    "#     row = dev_df_.iloc[i]\n",
    "#     text = row['Text']\n",
    "#     if text[row['A-offset']] != 'J':\n",
    "#         print('J')\n",
    "#         print(text)\n",
    "#         print(text[row['A-offset']:row['A-offset']+10] )\n",
    "#         print(dev_df.iloc[i][['Text', 'A', 'B']])\n",
    "#     if text[row['B-offset']] != 'B':\n",
    "#         print('B')\n",
    "#         print(text)\n",
    "#         print(text[row['B-offset']:row['B-offset']+10] )\n",
    "#         print(dev_df.iloc[i][['Text', 'A', 'B']])\n",
    "\n",
    "\n",
    "# encode\n",
    "# dev_embed_file_name = \"dev_embed.json\"\n",
    "# encode_by_bert(dev_df_, dev_embed_file_name)\n",
    "# os.system(\"rm \" + dev_embed_file_name)\n",
    "# # split\n",
    "# # split_embed_files(dev_embed_file_name, 32, embed_folder, \"dev_embed\")\n",
    "# print(\"Finished at \", time.ctime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "8298947fa33285e722bdaae2df41bca5dd795732"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started at  Mon Apr  8 02:41:49 2019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished at  Mon Apr  8 02:42:19 2019\n",
      "Finished at  Mon Apr  8 02:42:22 2019\n",
      "Finished at  Mon Apr  8 02:42:39 2019\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Started at \", time.ctime())\n",
    "\n",
    "train_embed_file_name = \"train_embed.json\"\n",
    "dev_embed_file_name = \"dev_embed.json\"\n",
    "test_embed_file_name = \"test_embed.json\"\n",
    "\n",
    "batch_size = 180\n",
    "\n",
    "# clip text\n",
    "text_clip_update(train_df, MAX_LEN)\n",
    "print(\"Finished at \", time.ctime())\n",
    "\n",
    "# clip text\n",
    "text_clip_update(dev_df, MAX_LEN)\n",
    "print(\"Finished at \", time.ctime())\n",
    "\n",
    "# clip text\n",
    "text_clip_update(test_df, MAX_LEN)\n",
    "print(\"Finished at \", time.ctime())\n",
    "\n",
    "del nlp\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "0a69bc95d2c44c400045b5bb65f7f49f69fde2ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num batches:23\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "num batches:3\n",
      "0\n",
      "1\n",
      "2\n",
      "num batches:12\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "Finished at  Mon Apr  8 04:29:06 2019\n"
     ]
    }
   ],
   "source": [
    "# encode\n",
    "encode_by_bert(train_df, batch_size, train_embed_file_name, embed_folder, \"train_embed\")\n",
    "encode_by_bert(dev_df, batch_size, dev_embed_file_name, embed_folder, \"dev_embed\")\n",
    "encode_by_bert(test_df, batch_size, test_embed_file_name, embed_folder, \"test_embed\")\n",
    "print(\"Finished at \", time.ctime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "5eac3b67a93c6412e0a622300887dc645f4a88f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__notebook__.ipynb  __output__.json  __pycache__  embs\r\n"
     ]
    }
   ],
   "source": [
    "os.system(\"rm -rdf \" + \"uncased_L-24_H-1024_A-16\")\n",
    "os.system(\"rm \" + \"bert*\")\n",
    "os.system(\"rm \" + \"vocab.text\")\n",
    "os.system(\"rm \" + \"extract_features*\")\n",
    "os.system(\"rm \" + \"modeling*\")\n",
    "os.system(\"rm \" + \"tokenization*\")\n",
    "!ls"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
